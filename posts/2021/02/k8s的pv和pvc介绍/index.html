<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><meta http-equiv=x-ua-compatible content="IE=edge, chrome=1"><title>K8S的PV和PVC介绍 - 斌哥的小站|Binge Blog</title><meta name=Description content="PV和PVC的概念和设计原理"><meta property="og:title" content="K8S的PV和PVC介绍"><meta property="og:description" content="PV和PVC的概念和设计原理"><meta property="og:type" content="article"><meta property="og:url" content="http://bingerambo.com/posts/2021/02/k8s%E7%9A%84pv%E5%92%8Cpvc%E4%BB%8B%E7%BB%8D/"><meta property="og:image" content="http://bingerambo.com/logo.png"><meta property="article:published_time" content="2021-02-03T08:43:17+08:00"><meta property="article:modified_time" content="2021-02-03T08:43:17+08:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://bingerambo.com/logo.png"><meta name=twitter:title content="K8S的PV和PVC介绍"><meta name=twitter:description content="PV和PVC的概念和设计原理"><meta name=application-name content="Binge Blog"><meta name=apple-mobile-web-app-title content="Binge Blog"><meta name=theme-color content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=canonical href=http://bingerambo.com/posts/2021/02/k8s%E7%9A%84pv%E5%92%8Cpvc%E4%BB%8B%E7%BB%8D/><link rel=prev href=http://bingerambo.com/posts/2021/01/hugepage%E9%85%8D%E7%BD%AE%E5%AF%BC%E8%87%B4k8s%E7%9A%84kubelet%E9%87%8D%E5%90%AF%E5%A4%B1%E8%B4%A5%E9%97%AE%E9%A2%98/><link rel=next href=http://bingerambo.com/posts/2021/02/k8s%E7%9A%84%E4%B8%9A%E5%8A%A1pod%E7%BB%84%E4%BB%B6%E7%9A%84invalid-token%E9%97%AE%E9%A2%98/><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/normalize.css@8.0.1/normalize.min.css><link rel=stylesheet href=/css/style.min.css><link rel=stylesheet href=/css/custom.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/animate.css@3.7.2/animate.min.css><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"K8S的PV和PVC介绍","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"http:\/\/bingerambo.com\/posts\/2021\/02\/k8s%E7%9A%84pv%E5%92%8Cpvc%E4%BB%8B%E7%BB%8D\/"},"image":["http:\/\/bingerambo.com\/images\/Apple-Devices-Preview.png"],"genre":"posts","keywords":"K8S","wordcount":14018,"url":"http:\/\/bingerambo.com\/posts\/2021\/02\/k8s%E7%9A%84pv%E5%92%8Cpvc%E4%BB%8B%E7%BB%8D\/","datePublished":"2021-02-03T08:43:17+08:00","dateModified":"2021-02-03T08:43:17+08:00","license":"This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher":{"@type":"Organization","name":"xxxx","logo":"http:\/\/bingerambo.com\/images\/avatar.png"},"author":{"@type":"Person","name":"Binge"},"description":"PV和PVC的概念和设计原理"}</script></head><body header-desktop=fixed header-mobile=auto><script type=text/javascript>(window.localStorage&&localStorage.getItem('theme')?localStorage.getItem('theme')==='dark':('auto'==='auto'?window.matchMedia('(prefers-color-scheme: dark)').matches:'auto'==='dark'))&&document.body.setAttribute('theme','dark');</script><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title="斌哥的小站|Binge Blog"><span class=header-title-pre><i class="fas fa-biking fa-fw"></i></span>Binge Blog</a></div><div class=menu><div class=menu-inner><a class=menu-item href=/posts/><i class="fas fa-fw fa-archive"></i>文章 </a><a class=menu-item href=/tags/><i class="fas fa-fw fa-tag"></i>标签 </a><a class=menu-item href=/categories/><i class="fas fa-fw fa-th"></i>分类 </a><a class=menu-item href=/timeline/><i class="fas fa-cog fa-spin"></i>随记 </a><a class=menu-item href=/about/><i class="fas fa-fw fa-at"></i>关于 </a><a class=menu-item href=/search/><i class="fas fa-fw fa-search"></i>搜索 </a><a class=menu-item href=/friend/ title=Friend><i class="fas fa fa-user"></i>友链 </a><a class=menu-item href=https://github.com/bingerambo title=GitHub rel="noopener noreffer" target=_blank><i class="fab fa-github fa-fw"></i></a><a class=menu-item href=/><i class="fas fa fa-eye"></i><span id=busuanzi_value_site_uv></span></a><span class="menu-item delimiter"></span><a href=javascript:void(0); class="menu-item theme-switch" title=切换主题><i class="fas fa-adjust fa-fw"></i></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="斌哥的小站|Binge Blog"><span class=header-title-pre><i class="fas fa-biking fa-fw"></i></span>Binge Blog</a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><a class=menu-item href=/posts/><i class="fas fa-fw fa-archive"></i>文章</a><a class=menu-item href=/tags/><i class="fas fa-fw fa-tag"></i>标签</a><a class=menu-item href=/categories/><i class="fas fa-fw fa-th"></i>分类</a><a class=menu-item href=/timeline/><i class="fas fa-cog fa-spin"></i>随记</a><a class=menu-item href=/about/><i class="fas fa-fw fa-at"></i>关于</a><a class=menu-item href=/search/><i class="fas fa-fw fa-search"></i>搜索</a><a class=menu-item href=/friend/ title=Friend><i class="fas fa fa-user"></i>友链</a><a class=menu-item href=https://github.com/bingerambo title=GitHub rel="noopener noreffer" target=_blank><i class="fab fa-github fa-fw"></i></a><a class=menu-item href=/><i class="fas fa fa-eye"></i><span id=busuanzi_value_site_uv></span></a><a href=javascript:void(0); class="menu-item theme-switch" title=切换主题>
<i class="fas fa-adjust fa-fw"></i></a></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>目录</h2><div class=toc-content id=toc-content-auto></div></div><article class="page single"><h1 class="single-title animated flipInX">K8S的PV和PVC介绍</h1><div class=post-meta><div class=post-meta-line><span class=post-author><a href=http://bingerambo.com title=Author target=_blank rel="noopener noreffer author" class=author><i class="fas fa-user-circle fa-fw"></i>Binge</a></span>&nbsp;<span class=post-category>收录于 <a href=/categories/k8s/><i class="far fa-folder fa-fw"></i>K8S</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime=2021-02-03>2021-02-03</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;约 14018 字&nbsp;
<i class="far fa-clock fa-fw"></i>&nbsp;预计阅读 28 分钟&nbsp;
<i class="fa fa-eye fa-fw"></i>&nbsp;本文总阅读量 <span id=busuanzi_value_page_pv></span>次&nbsp;</div></div><div class="details toc" id=toc-static kept><div class="details-summary toc-title"><span>目录</span>
<span><i class="details-icon fas fa-angle-right"></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#k8s的pv和pvc概念>k8s的PV和PVC概念</a><ul><li><a href=#卷>卷</a><ul><li><a href=#configmap>configMap</a></li><li><a href=#emptydir>emptyDir</a></li><li><a href=#hostpath>hostPath</a></li><li><a href=#secret>Secret</a></li><li><a href=#nfs>nfs</a></li></ul></li><li><a href=#持久卷>持久卷</a><ul><li><a href=#供应>供应</a><ul><li><a href=#静态供应>静态供应</a></li><li><a href=#动态供应>动态供应</a></li></ul></li><li><a href=#绑定>绑定</a></li><li><a href=#使用>使用</a></li><li><a href=#保护使用中的存储对象>保护使用中的存储对象</a></li><li><a href=#pv说明>PV说明</a><ul><li><a href=#容量>容量</a></li><li><a href=#卷模式>卷模式</a></li><li><a href=#访问模式>访问模式</a></li><li><a href=#类>类</a></li><li><a href=#回收策略>回收策略</a></li><li><a href=#节点亲和性>节点亲和性</a></li><li><a href=#pv的阶段>PV的阶段</a></li></ul></li><li><a href=#pvc说明>PVC说明</a><ul><li><a href=#访问模式-1>访问模式</a></li><li><a href=#卷模式-1>卷模式</a></li><li><a href=#资源>资源</a></li><li><a href=#选择算符>选择算符</a></li><li><a href=#类-1>类</a></li><li><a href=#使用申领作为卷>使用申领作为卷</a></li></ul></li></ul></li></ul></li><li><a href=#pv和pvc设计目标>PV和PVC设计目标</a></li><li><a href=#persistentvolumecontroller分析>PersistentVolumeController分析</a><ul><li><a href=#实例化>实例化</a></li><li><a href=#pv-cache-构造>pv cache 构造</a></li><li><a href=#为pvc匹配查找最佳pv>为pvc匹配查找最佳pv</a></li></ul></li><li><a href=#matching-and-binding-pvc-pv>Matching and binding PVC->PV</a></li><li><a href=#测试nfs-pv-pvc>测试NFS-PV-PVC</a><ul><li><a href=#nfs-server>nfs server</a></li><li><a href=#nfs-server-part>NFS server part</a></li><li><a href=#测试的pv和pvc信息>测试的pv和pvc信息</a></li><li><a href=#部署>部署</a></li><li><a href=#卸载>卸载</a></li></ul></li><li><a href=#问题>问题</a><ul><li><a href=#output-mountnfs-protocol-not-supported>Output: mount.nfs: Protocol not supported</a></li><li><a href=#访问挂载路径服务端access-denied>访问挂载路径，服务端access denied</a></li></ul></li><li><a href=#附录>附录</a><ul><li><a href=#custom-nfs-server-rcyaml>custom-nfs-server-rc.yaml</a></li><li><a href=#custom-nfs-pvyaml>custom-nfs-pv.yaml</a></li><li><a href=#custom-nfs-pvcyaml>custom-nfs-pvc.yaml</a></li><li><a href=#custom-nfs-busybox-rcyaml>custom-nfs-busybox-rc.yaml</a></li><li><a href=#nfs-web-rcyaml>nfs-web-rc.yaml</a></li></ul></li><li><a href=#参考资料>参考资料</a></li></ul></nav></div></div><div class=content id=content><p>介绍K8S的PV和PVC概念和设计原理。</p><h2 id=k8s的pv和pvc概念>k8s的PV和PVC概念</h2><h3 id=卷>卷</h3><p>Container 中的文件在磁盘上是临时存放的，这给 Container 中运行的较重要的应用 程序带来一些问题。</p><ol><li>问题之一是当容器崩溃时文件丢失。kubelet 会重新启动容器， 但容器会以干净的状态重启。</li><li>第二个问题会在同一 Pod 中运行多个容器并共享文件时出现。</li></ol><p><a href=https://kubernetes.io/zh/docs/concepts/storage/volumes/ target=_blank rel="noopener noreffer">Kubernetes 卷（Volume）</a> 这一抽象概念能够解决这两个问题。</p><p>Kubernetes 支持很多类型的卷。 Pod 可以同时使用任意数目的卷类型。 临时卷类型的生命周期与 Pod 相同，但持久卷可以比 Pod 的存活期长。 因此，卷的存在时间会超出 Pod 中运行的所有容器，并且在容器重新启动时数据也会得到保留。 当 Pod 不再存在时，卷也将不再存在。</p><p>卷的核心是包含一些数据的一个目录，Pod 中的容器可以访问该目录。 所采用的特定的卷类型将决定该目录如何形成的、使用何种介质保存数据以及目录中存放 的内容。</p><h4 id=configmap>configMap</h4><p>configMap 卷 提供了向 Pod 注入配置数据的方法。 ConfigMap 对象中存储的数据可以被 configMap 类型的卷引用，然后被 Pod 中运行的 容器化应用使用。</p><p>引用 configMap 对象时，你可以在 volume 中通过它的名称来引用。 你可以自定义 ConfigMap 中特定条目所要使用的路径。 下面的配置显示了如何将名为 log-config 的 ConfigMap 挂载到名为 configmap-pod 的 Pod 中：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-yaml data-lang=yaml><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>v1</span><span class=w>
</span><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>Pod</span><span class=w>
</span><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>configmap-pod</span><span class=w>
</span><span class=w></span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>containers</span><span class=p>:</span><span class=w>
</span><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>test</span><span class=w>
</span><span class=w>      </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>busybox</span><span class=w>
</span><span class=w>      </span><span class=nt>volumeMounts</span><span class=p>:</span><span class=w>
</span><span class=w>        </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>config-vol</span><span class=w>
</span><span class=w>          </span><span class=nt>mountPath</span><span class=p>:</span><span class=w> </span><span class=l>/etc/config</span><span class=w>
</span><span class=w>  </span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>config-vol</span><span class=w>
</span><span class=w>      </span><span class=nt>configMap</span><span class=p>:</span><span class=w>
</span><span class=w>        </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>log-config</span><span class=w>
</span><span class=w>        </span><span class=nt>items</span><span class=p>:</span><span class=w>
</span><span class=w>          </span>- <span class=nt>key</span><span class=p>:</span><span class=w> </span><span class=l>log_level</span><span class=w>
</span><span class=w>            </span><span class=nt>path</span><span class=p>:</span><span class=w> </span><span class=l>log_level</span><span class=w>
</span></code></pre></td></tr></table></div></div><p>log-config ConfigMap 以卷的形式挂载，并且存储在 log_level 条目中的所有内容 都被挂载到 Pod 的 /etc/config/log_level 路径下。 请注意，这个路径来源于卷的 mountPath 和 log_level 键对应的 path。</p><blockquote><p>说明：</p><ul><li>在使用 ConfigMap 之前你首先要创建它。</li><li>容器以 subPath 卷挂载方式使用 ConfigMap 时，将无法接收 ConfigMap 的更新。</li><li>文本数据挂载成文件时采用 UTF-8 字符编码。如果使用其他字符编码形式，可使用 binaryData 字段。</li></ul></blockquote><h4 id=emptydir>emptyDir</h4><p>当 Pod 分派到某个 Node 上时，emptyDir 卷会被创建，并且在 Pod 在该节点上运行期间，卷一直存在。 就像其名称表示的那样，卷最初是空的。 尽管 Pod 中的容器挂载 emptyDir 卷的路径可能相同也可能不同，这些容器都可以读写 emptyDir 卷中相同的文件。 当 Pod 因为某些原因被从节点上删除时，emptyDir 卷中的数据也会被永久删除。</p><p>说明： 容器崩溃并不会导致 Pod 被从节点上移除，因此容器崩溃期间 emptyDir 卷中的数据是安全的。
emptyDir 的一些用途：</p><ul><li>缓存空间，例如基于磁盘的归并排序。</li><li>为耗时较长的计算任务提供检查点，以便任务能方便地从崩溃前状态恢复执行。</li><li>在 Web 服务器容器服务数据时，保存内容管理器容器获取的文件。</li></ul><h4 id=hostpath>hostPath</h4><p>hostPath 卷能将主机节点文件系统上的文件或目录挂载到你的 Pod 中。 虽然这不是大多数 Pod 需要的，但是它为一些应用程序提供了强大的逃生舱。</p><p>例如，hostPath 的一些用法有：</p><p>运行一个需要访问 Docker 内部机制的容器；可使用 hostPath 挂载 /var/lib/docker 路径。
在容器中运行 cAdvisor 时，以 hostPath 方式挂载 /sys。
允许 Pod 指定给定的 hostPath 在运行 Pod 之前是否应该存在，是否应该创建以及应该以什么方式存在。
除了必需的 path 属性之外，用户可以选择性地为 hostPath 卷指定 type。</p><h4 id=secret>Secret</h4><p>secret 卷用来给 Pod 传递敏感信息，例如密码。你可以将 Secret 存储在 Kubernetes API 服务器上，然后以文件的形式挂在到 Pod 中，无需直接与 Kubernetes 耦合。 secret 卷由 tmpfs（基于 RAM 的文件系统）提供存储，因此它们永远不会被写入非易失性 （持久化的）存储器。</p><blockquote><p>说明： 使用前你必须在 Kubernetes API 中创建 secret。
说明： 容器以 subPath 卷挂载方式挂载 Secret 时，将感知不到 Secret 的更新。</p></blockquote><p>secret说明文档：https://kubernetes.io/zh/docs/concepts/configuration/secret/</p><h4 id=nfs>nfs</h4><p>nfs 卷能将 NFS (网络文件系统) 挂载到你的 Pod 中。 不像 emptyDir 那样会在删除 Pod 的同时也会被删除，nfs 卷的内容在删除 Pod 时会被保存，卷只是被卸载。 这意味着 nfs 卷可以被预先填充数据，并且这些数据可以在 Pod 之间共享。</p><p>注意： 在使用 NFS 卷之前，你必须运行自己的 NFS 服务，并将目标 share 导出备用。</p><p><a href=https://github.com/kubernetes/examples/tree/master/staging/volumes/nfs target=_blank rel="noopener noreffer">nfs示例</a></p><p>persistentVolumeClaim
persistentVolumeClaim 卷用来将持久卷（PersistentVolume） 挂载到 Pod 中。 持久卷声明（PersistentVolumeClaim）是用户在不知道特定云环境细节的情况下"声明"持久存储 （例如 GCE PersistentDisk 或者 iSCSI 卷）的一种方法。</p><p>更多详情请参考<a href=##%e6%8c%81%e4%b9%85%e5%8d%b7 rel>持久卷示例</a></p><h3 id=持久卷>持久卷</h3><p><a href=https://kubernetes.io/zh/docs/concepts/storage/persistent-volumes/ target=_blank rel="noopener noreffer">persistent-volumes概念</a></p><p>存储的管理是一个与计算实例的管理完全不同的问题。PersistentVolume 子系统为用户 和管理员提供了一组 API，将存储如何供应的细节从其如何被使用中抽象出来。 为了实现这点，我们引入了两个新的 API 资源：PersistentVolume 和 PersistentVolumeClaim。</p><p>持久卷（PersistentVolume，PV）是集群中的一块存储，可以由管理员事先供应，或者 使用存储类（Storage Class）来动态供应。 持久卷是集群资源，就像节点也是集群资源一样。PV 持久卷和普通的 Volume 一样，也是使用 卷插件来实现的，只是它们拥有独立于任何使用 PV 的 Pod 的生命周期。 此 API 对象中记述了存储的实现细节，无论其背后是 NFS、iSCSI 还是特定于云平台的存储系统。</p><p>持久卷声明（PersistentVolumeClaim，PVC）表达的是用户对存储的请求。概念上与 Pod 类似。 Pod 会耗用节点资源，而 PVC 声明会耗用 PV 资源。Pod 可以请求特定数量的资源（CPU 和内存）；同样 PVC 声明也可以请求特定的大小和访问模式 （例如，可以要求 PV 卷能够以 ReadWriteOnce、ReadOnlyMany 或 ReadWriteMany 模式之一来挂载，参见访问模式）。</p><p>尽管 PersistentVolumeClaim 允许用户消耗抽象的存储资源，常见的情况是针对不同的 问题用户需要的是具有不同属性（如，性能）的 PersistentVolume 卷。 集群管理员需要能够提供不同性质的 PersistentVolume，并且这些 PV 卷之间的差别不 仅限于卷大小和访问模式，同时又不能将卷是如何实现的这些细节暴露给用户。 为了满足这类需求，就有了 存储类（StorageClass） 资源。</p><img src=pv-pvc-usage.png style=width:100%><p>PV不属于任何命名空间, 它跟节点（node）一样是集群层面的资源，区别于pod和PVC。由系统管理员创建管理。</p><img src=pv-pvc.png style=width:100%>
当集群用户需要在其pod中使用持久化存储时，他们首先创建PVC清单，指定所需要的最低容量要求和访问模式，然后用户将待久卷声明清单提交给Kubernetes API服务器，Kubernetes将找到可匹配的PV并将其绑定到PVC。PVC可以当作pod中的一个卷来使用，其他用户不能使用相同的PV，除非先通过删除PVC绑定来释放。<h4 id=供应>供应</h4><p>PV 卷的供应有两种方式：静态供应或动态供应。</p><h5 id=静态供应>静态供应</h5><p>集群管理员创建若干 PV 卷。这些卷对象带有真实存储的细节信息，并且对集群 用户可用（可见）。PV 卷对象存在于 Kubernetes API 中，可供用户消费（使用）。</p><h5 id=动态供应>动态供应</h5><p>如果管理员所创建的所有静态 PV 卷都无法与用户的 PersistentVolumeClaim 匹配， 集群可以尝试为该 PVC 申领动态供应一个存储卷。 这一供应操作是基于 StorageClass 来实现的：PVC 申领必须请求某个 存储类，同时集群管理员必须 已经创建并配置了该类，这样动态供应卷的动作才会发生。 如果 PVC 申领指定存储类为 &ldquo;"，则相当于为自身禁止使用动态供应的卷。</p><p>为了基于存储类完成动态的存储供应，集群管理员需要在 API 服务器上启用 DefaultStorageClass 准入控制器。 举例而言，可以通过保证 DefaultStorageClass 出现在 API 服务器组件的 &ndash;enable-admission-plugins 标志值中实现这点；该标志的值可以是逗号 分隔的有序列表。关于 API 服务器标志的更多信息，可以参考 kube-apiserver 文档。</p><h4 id=绑定>绑定</h4><p>用户创建一个带有特定存储容量和特定访问模式需求的 PersistentVolumeClaim 对象； 在动态供应场景下，这个 PVC 对象可能已经创建完毕。 主控节点中的控制回路监测新的 PVC 对象，寻找与之匹配的 PV 卷（如果可能的话）， 并将二者绑定到一起。 如果为了新的 PVC 申领动态供应了 PV 卷，则控制回路总是将该 PV 卷绑定到这一 PVC 申领。 否则，用户总是能够获得他们所请求的资源，只是所获得的 PV 卷可能会超出所请求的配置。 一旦绑定关系建立，则 PersistentVolumeClaim 绑定就是排他性的，<strong>无论该 PVC 申领是 如何与 PV 卷建立的绑定关系。 PVC 申领与 PV 卷之间的绑定是一种一对一的映射，实现上使用 ClaimRef 来记述 PV 卷 与 PVC 申领间的双向绑定关系</strong>。</p><p>如果找不到匹配的 PV 卷，PVC 申领会无限期地处于未绑定状态（即pvc处于pending状态）。 当与之匹配的 PV 卷可用时，PVC 申领会被绑定。 例如，即使某集群上供应了很多 50 Gi 大小的 PV 卷，也无法与请求 100 Gi 大小的存储的 PVC 匹配。当新的 100 Gi PV 卷被加入到集群时，该 PVC 才有可能被绑定。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=o>[</span>root@node131 k8s_pv_pvc<span class=o>]</span><span class=c1># kubectl get pvc -A</span>
NAMESPACE   NAME                       STATUS    VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   AGE
default     nfs-pv-provisioning-demo   Pending                                                     7s
<span class=o>[</span>root@node131 k8s_pv_pvc<span class=o>]</span><span class=c1>#</span>
<span class=o>[</span>root@node131 k8s_pv_pvc<span class=o>]</span><span class=c1># kubectl describe  pvc nfs-pv-provisioning-demo</span>
Name:          nfs-pv-provisioning-demo
Namespace:     default
StorageClass:
Status:        Pending
Volume:
Labels:        <span class=nv>demo</span><span class=o>=</span>nfs-pv-provisioning
Annotations:   &lt;none&gt;
Finalizers:    <span class=o>[</span>kubernetes.io/pvc-protection<span class=o>]</span>
Capacity:
Access Modes:
VolumeMode:    Filesystem
Used By:       &lt;none&gt;
Events:
  Type    Reason         Age               From                         Message
  ----    ------         ----              ----                         -------
  Normal  FailedBinding  5s <span class=o>(</span>x3 over 27s<span class=o>)</span>  persistentvolume-controller  no persistent volumes available <span class=k>for</span> this claim and no storage class is <span class=nb>set</span>
<span class=o>[</span>root@node131 k8s_pv_pvc<span class=o>]</span><span class=c1>#</span>

</code></pre></td></tr></table></div></div><h4 id=使用>使用</h4><p>Pod 将 PVC 申领当做存储卷来使用。集群会检视 PVC 申领，找到所绑定的卷，并 为 Pod 挂载该卷。对于支持多种访问模式的卷，用户要在 Pod 中以卷的形式使用申领 时指定期望的访问模式。</p><p>一旦用户有了申领对象并且该申领已经被绑定，则所绑定的 PV 卷在用户仍然需要它期间 一直属于该用户。用户通过在 Pod 的 volumes 块中包含 persistentVolumeClaim 节区来调度 Pod，访问所申领的 PV 卷。 相关细节可参阅使用申领作为卷。</p><h4 id=保护使用中的存储对象>保护使用中的存储对象</h4><p>保护使用中的存储对象（Storage Object in Use Protection）这一功能特性的目的 是确保仍被 Pod 使用的 PersistentVolumeClaim（PVC）对象及其所绑定的 PersistentVolume（PV）对象在系统中不会被删除，因为这样做可能会引起数据丢失。</p><blockquote><p>说明： 当使用某 PVC 的 Pod 对象仍然存在时，认为该 PVC 仍被此 Pod 使用。
如果用户删除被某 Pod 使用的 PVC 对象，该 PVC 申领不会被立即移除。 PVC 对象的移除会被推迟，直至其不再被任何 Pod 使用。 此外，如果管理员删除已绑定到某 PVC 申领的 PV 卷，该 PV 卷也不会被立即移除。 PV 对象的移除也要推迟到该 PV 不再绑定到 PVC。</p></blockquote><p>你可以看到当 PVC 的状态为 Terminating 且其 Finalizers 列表中包含 kubernetes.io/pvc-protection 时，PVC 对象是处于被保护状态的。</p><p>每个 PV 对象都包含 spec 部分和 status 部分，分别对应卷的规约和状态。 PersistentVolume 对象的名称必须是合法的 DNS 子域名.</p><h4 id=pv说明>PV说明</h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-yaml data-lang=yaml><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>v1</span><span class=w>
</span><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>PersistentVolume</span><span class=w>
</span><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>pv0003</span><span class=w>
</span><span class=w></span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>capacity</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>storage</span><span class=p>:</span><span class=w> </span><span class=l>5Gi</span><span class=w>
</span><span class=w>  </span><span class=nt>volumeMode</span><span class=p>:</span><span class=w> </span><span class=l>Filesystem</span><span class=w>
</span><span class=w>  </span><span class=nt>accessModes</span><span class=p>:</span><span class=w>
</span><span class=w>    </span>- <span class=l>ReadWriteOnce</span><span class=w>
</span><span class=w>  </span><span class=nt>persistentVolumeReclaimPolicy</span><span class=p>:</span><span class=w> </span><span class=l>Recycle</span><span class=w>
</span><span class=w>  </span><span class=nt>storageClassName</span><span class=p>:</span><span class=w> </span><span class=l>slow</span><span class=w>
</span><span class=w>  </span><span class=nt>mountOptions</span><span class=p>:</span><span class=w>
</span><span class=w>    </span>- <span class=l>hard</span><span class=w>
</span><span class=w>    </span>- <span class=l>nfsvers=4.1</span><span class=w>
</span><span class=w>  </span><span class=nt>nfs</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>path</span><span class=p>:</span><span class=w> </span><span class=l>/tmp</span><span class=w>
</span><span class=w>    </span><span class=nt>server</span><span class=p>:</span><span class=w> </span><span class=m>192.168.182.131</span><span class=w>
</span></code></pre></td></tr></table></div></div><blockquote><p>说明： 在集群中使用持久卷存储通常需要一些特定于具体卷类型的辅助程序。 在这个例子中，PersistentVolume 是 NFS 类型的，因此需要辅助程序 /sbin/mount.nfs 来支持挂载 NFS 文件系统。</p></blockquote><h5 id=容量>容量</h5><p>一般而言，每个 PV 卷都有确定的存储容量。 容量属性是使用 PV 对象的 capacity 属性来设置的。 参考 Kubernetes 资源模型（Resource Model） 设计提案，了解 capacity 字段可以接受的单位。</p><p>目前，存储大小是可以设置和请求的唯一资源。 未来可能会包含 IOPS、吞吐量等属性。</p><h5 id=卷模式>卷模式</h5><p>FEATURE STATE: Kubernetes v1.18 [stable]
针对 PV 持久卷，Kuberneretes 支持两种卷模式（volumeModes）：Filesystem（文件系统） 和 Block（块）。 volumeMode 是一个可选的 API 参数。 如果该参数被省略，默认的卷模式是 Filesystem。</p><p>volumeMode 属性设置为 Filesystem 的卷会被 Pod 挂载（Mount） 到某个目录。 如果卷的存储来自某块设备而该设备目前为空，Kuberneretes 会在第一次挂载卷之前 在设备上创建文件系统。</p><p>你可以将 volumeMode 设置为 Block，以便将卷作为原始块设备来使用。 这类卷以块设备的方式交给 Pod 使用，其上没有任何文件系统。 这种模式对于为 Pod 提供一种使用最快可能方式来访问卷而言很有帮助，Pod 和 卷之间不存在文件系统层。另外，Pod 中运行的应用必须知道如何处理原始块设备。 关于如何在 Pod 中使用 volumeMode: Block 的卷，可参阅 原始块卷支持。</p><h5 id=访问模式>访问模式</h5><p>PersistentVolume 卷可以用资源提供者所支持的任何方式挂载到宿主系统上。 如下表所示，提供者（驱动）的能力不同，每个 PV 卷的访问模式都会设置为 对应卷所支持的模式值。 例如，NFS 可以支持多个读写客户，但是某个特定的 NFS PV 卷可能在服务器 上以只读的方式导出。每个 PV 卷都会获得自身的访问模式集合，描述的是 特定 PV 卷的能力。</p><p>访问模式有：</p><ul><li>ReadWriteOnce &ndash; 卷可以被一个节点以读写方式挂载；</li><li>ReadOnlyMany &ndash; 卷可以被多个节点以只读方式挂载；</li><li>ReadWriteMany &ndash; 卷可以被多个节点以读写方式挂载。</li></ul><p>在命令行接口（CLI）中，访问模式也使用以下缩写形式：</p><ul><li>RWO - ReadWriteOnce</li><li>ROX - ReadOnlyMany</li><li>RWX - ReadWriteMany</li></ul><blockquote><p>重要提醒！ 每个卷只能同一时刻只能以一种访问模式挂载，即使该卷能够支持 多种访问模式。例如，一个 GCEPersistentDisk 卷可以被某节点以 ReadWriteOnce 模式挂载，或者被多个节点以 ReadOnlyMany 模式挂载，但不可以同时以两种模式 挂载。</p></blockquote><h5 id=类>类</h5><p>每个 PV 可以属于某个类（Class），通过将其 storageClassName 属性设置为某个 StorageClass 的名称来指定。 特定类的 PV 卷只能绑定到请求该类存储卷的 PVC 申领。 未设置 storageClassName 的 PV 卷没有类设定，只能绑定到那些没有指定特定 存储类的 PVC 申领。</p><p>早前，Kubernetes 使用注解 volume.beta.kubernetes.io/storage-class 而不是 storageClassName 属性。这一注解目前仍然起作用，不过在将来的 Kubernetes 发布版本中该注解会被彻底废弃。</p><h5 id=回收策略>回收策略</h5><p>目前的回收策略有：</p><ul><li>Retain &ndash; 手动回收</li><li>Recycle &ndash; 基本擦除 (rm -rf /thevolume/*)</li><li>Delete &ndash; 诸如 AWS EBS、GCE PD、Azure Disk 或 OpenStack Cinder 卷这类关联存储资产也被删除</li></ul><p>目前，仅 NFS 和 HostPath 支持回收（Recycle）。 AWS EBS、GCE PD、Azure Disk 和 Cinder 卷都支持删除（Delete）。</p><blockquote><p>回收策略 Retain 使得用户可以手动回收资源。当 PersistentVolumeClaim 对象 被删除时，PersistentVolume 卷仍然存在，对应的数据卷被视为"已释放（released）"。 由于卷上仍然存在这前一申领人的数据，该卷还不能用于其他申领。</p></blockquote><p>测试Retain模式如下：
说明：Retain模式下，删除以前绑定pv的pvc后，再创建使用该pv的pvc，会导致该pvc一直pending。因为pv的Claim: default/nfs字段导致。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-shell data-lang=shell><span class=o>[</span>root@node131 ~<span class=o>]</span><span class=c1>#</span>
<span class=o>[</span>root@node131 ~<span class=o>]</span><span class=c1># kubectl get pv</span>
NAME   CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM         STORAGECLASS   REASON   AGE
nfs    1Mi        RWX            Retain           Bound    default/nfs                           5h58m
<span class=o>[</span>root@node131 ~<span class=o>]</span>
<span class=o>[</span>root@node131 k8s_pv_pvc<span class=o>]</span><span class=c1># kubectl delete -f nfs/nfs-pvc.yaml</span>
persistentvolumeclaim <span class=s2>&#34;nfs&#34;</span> deleted
<span class=o>[</span>root@node131 k8s_pv_pvc<span class=o>]</span><span class=c1>#</span>
<span class=o>[</span>root@node131 k8s_pv_pvc<span class=o>]</span><span class=c1>#</span>
<span class=o>[</span>root@node131 ~<span class=o>]</span><span class=c1>#</span>
<span class=o>[</span>root@node131 ~<span class=o>]</span><span class=c1>#</span>
<span class=o>[</span>root@node131 ~<span class=o>]</span><span class=c1># kubectl get pv</span>
NAME   CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS     CLAIM         STORAGECLASS   REASON   AGE
nfs    1Mi        RWX            Retain           Released   default/nfs                           6h1m
<span class=o>[</span>root@node131 ~<span class=o>]</span><span class=c1>#</span>
<span class=o>[</span>root@node131 k8s_pv_pvc<span class=o>]</span><span class=c1># kubectl create -f nfs/custom-nfs-pvc.yaml</span>
persistentvolumeclaim/nfs created
<span class=o>[</span>root@node131 k8s_pv_pvc<span class=o>]</span><span class=c1>#</span>
<span class=o>[</span>root@node131 ~<span class=o>]</span><span class=c1>#</span>
<span class=o>[</span>root@node131 ~<span class=o>]</span><span class=c1># kubectl get pvc</span>
NAME   STATUS    VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   AGE
nfs    Pending                                                     8s
<span class=o>[</span>root@node131 ~<span class=o>]</span><span class=c1>#</span>
<span class=o>[</span>root@node131 ~<span class=o>]</span><span class=c1>#</span>
<span class=o>[</span>root@node131 ~<span class=o>]</span><span class=c1># kubectl describe pv</span>
Name:            nfs
Labels:          &lt;none&gt;
Annotations:     pv.kubernetes.io/bound-by-controller: yes
Finalizers:      <span class=o>[</span>kubernetes.io/pv-protection<span class=o>]</span>
StorageClass:
Status:          Released
Claim:           default/nfs
Reclaim Policy:  Retain
Access Modes:    RWX
VolumeMode:      Filesystem
Capacity:        1Mi
Node Affinity:   &lt;none&gt;
Message:
Source:
    Type:      NFS <span class=o>(</span>an NFS mount that lasts the lifetime of a pod<span class=o>)</span>
    Server:    10.233.16.102
    Path:      /exports
    ReadOnly:  <span class=nb>false</span>
Events:        &lt;none&gt;


</code></pre></td></tr></table></div></div><h5 id=节点亲和性>节点亲和性</h5><p>每个 PV 卷可以通过设置 节点亲和性 来定义一些约束，进而限制从哪些节点上可以访问此卷。 使用这些卷的 Pod 只会被调度到节点亲和性规则所选择的节点上执行。</p><blockquote><p>说明： 对大多数类型的卷而言，你不需要设置节点亲和性字段。 AWS EBS、 GCE PD 和 Azure Disk 卷类型都能 自动设置相关字段。 你需要为 local 卷显式地设置 此属性</p></blockquote><h5 id=pv的阶段>PV的阶段</h5><p>每个卷会处于以下阶段（Phase）之一：</p><ul><li>Available（可用）&ndash; 卷是一个空闲资源，尚未绑定到任何申领；</li><li>Bound（已绑定）&ndash; 该卷已经绑定到某申领；</li><li>Released（已释放）&ndash; 所绑定的申领已被删除，但是资源尚未被集群回收；</li><li>Failed（失败）&ndash; 卷的自动回收操作失败。
命令行接口能够显示绑定到某 PV 卷的 PVC 对象</li></ul><h4 id=pvc说明>PVC说明</h4><p>每个 PVC 对象都有 spec 和 status 部分，分别对应申领的规约和状态。 PersistentVolumeClaim 对象的名称必须是合法的 DNS 子域名.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-yaml data-lang=yaml><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>v1</span><span class=w>
</span><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>PersistentVolumeClaim</span><span class=w>
</span><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>myclaim</span><span class=w>
</span><span class=w></span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>accessModes</span><span class=p>:</span><span class=w>
</span><span class=w>    </span>- <span class=l>ReadWriteOnce</span><span class=w>
</span><span class=w>  </span><span class=nt>volumeMode</span><span class=p>:</span><span class=w> </span><span class=l>Filesystem</span><span class=w>
</span><span class=w>  </span><span class=nt>resources</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>requests</span><span class=p>:</span><span class=w>
</span><span class=w>      </span><span class=nt>storage</span><span class=p>:</span><span class=w> </span><span class=l>8Gi</span><span class=w>
</span><span class=w>  </span><span class=nt>storageClassName</span><span class=p>:</span><span class=w> </span><span class=l>slow</span><span class=w>
</span><span class=w>  </span><span class=nt>selector</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>matchLabels</span><span class=p>:</span><span class=w>
</span><span class=w>      </span><span class=nt>release</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;stable&#34;</span><span class=w>
</span><span class=w>    </span><span class=nt>matchExpressions</span><span class=p>:</span><span class=w>
</span><span class=w>      </span>- {<span class=nt>key: environment, operator: In, values</span><span class=p>:</span><span class=w> </span><span class=p>[</span><span class=l>dev]}</span><span class=w>
</span></code></pre></td></tr></table></div></div><h5 id=访问模式-1>访问模式</h5><p>申领在请求具有特定访问模式的存储时，使用与卷相同的访问模式约定。</p><h5 id=卷模式-1>卷模式</h5><p>申领使用与卷相同的约定来表明是将卷作为文件系统还是块设备来使用。</p><h5 id=资源>资源</h5><p>申领和 Pod 一样，也可以请求特定数量的资源。在这个上下文中，请求的资源是存储。 卷和申领都使用相同的 资源模型。</p><h5 id=选择算符>选择算符</h5><p>申领可以设置标签选择算符 来进一步过滤卷集合。只有标签与选择算符相匹配的卷能够绑定到申领上。 选择算符包含两个字段：</p><p>matchLabels - 卷必须包含带有此值的标签
matchExpressions - 通过设定键（key）、值列表和操作符（operator） 来构造的需求。合法的操作符有 In、NotIn、Exists 和 DoesNotExist。
来自 matchLabels 和 matchExpressions 的所有需求都按逻辑与的方式组合在一起。 这些需求都必须被满足才被视为匹配。</p><h5 id=类-1>类</h5><p>申领可以通过为 storageClassName 属性设置 StorageClass 的名称来请求特定的存储类。 只有所请求的类的 PV 卷，即 storageClassName 值与 PVC 设置相同的 PV 卷， 才能绑定到 PVC 申领。</p><p>PVC 申领不必一定要请求某个类。如果 PVC 的 storageClassName 属性值设置为 &ldquo;"， 则被视为要请求的是没有设置存储类的 PV 卷，因此这一 PVC 申领只能绑定到未设置 存储类的 PV 卷（未设置注解或者注解值为 "&rdquo; 的 PersistentVolume（PV）对象在系统中不会被删除，因为这样做可能会引起数据丢失。 未设置 storageClassName 的 PVC 与此大不相同，也会被集群作不同处理。 具体筛查方式取决于 DefaultStorageClass 准入控制器插件 是否被启用。</p><ul><li>如果准入控制器插件被启用，则管理员可以设置一个默认的 StorageClass。 所有未设置 storageClassName 的 PVC 都只能绑定到隶属于默认存储类的 PV 卷。 设置默认 StorageClass 的工作是通过将对应 StorageClass 对象的注解 storageclass.kubernetes.io/is-default-class 赋值为 true 来完成的。 如果管理员未设置默认存储类，集群对 PVC 创建的处理方式与未启用准入控制器插件 时相同。如果设定的默认存储类不止一个，准入控制插件会禁止所有创建 PVC 操作。</li><li>如果准入控制器插件被关闭，则不存在默认 StorageClass 的说法。 所有未设置 storageClassName 的 PVC 都只能绑定到未设置存储类的 PV 卷。 在这种情况下，未设置 storageClassName 的 PVC 与 storageClassName 设置未 "&rdquo; 的 PVC 的处理方式相同。</li></ul><p>取决于安装方法，默认的 StorageClass 可能在集群安装期间由插件管理器（Addon Manager）部署到集群中。</p><p>当某 PVC 除了请求 StorageClass 之外还设置了 selector，则这两种需求会按 逻辑与关系处理：只有隶属于所请求类且带有所请求标签的 PV 才能绑定到 PVC。</p><blockquote><p>说明： 目前，设置了非空 selector 的 PVC 对象无法让集群为其动态供应 PV 卷。</p></blockquote><p>早前，Kubernetes 使用注解 volume.beta.kubernetes.io/storage-class 而不是 storageClassName 属性。这一注解目前仍然起作用，不过在将来的 Kubernetes 发布版本中该注解会被彻底废弃。</p><h5 id=使用申领作为卷>使用申领作为卷</h5><p>Pod 将申领作为卷来使用，并藉此访问存储资源。 申领必须位于使用它的 Pod 所在的同一名字空间内。 集群在 Pod 的名字空间中查找申领，并使用它来获得申领所使用的 PV 卷。 之后，卷会被挂载到宿主上并挂载到 Pod 中。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-yaml data-lang=yaml><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>v1</span><span class=w>
</span><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>Pod</span><span class=w>
</span><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>mypod</span><span class=w>
</span><span class=w></span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>containers</span><span class=p>:</span><span class=w>
</span><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>myfrontend</span><span class=w>
</span><span class=w>      </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>nginx</span><span class=w>
</span><span class=w>      </span><span class=nt>volumeMounts</span><span class=p>:</span><span class=w>
</span><span class=w>      </span>- <span class=nt>mountPath</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;/var/www/html&#34;</span><span class=w>
</span><span class=w>        </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>mypd</span><span class=w>
</span><span class=w>  </span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>mypd</span><span class=w>
</span><span class=w>      </span><span class=nt>persistentVolumeClaim</span><span class=p>:</span><span class=w>
</span><span class=w>        </span><span class=nt>claimName</span><span class=p>:</span><span class=w> </span><span class=l>myclaim</span><span class=w>
</span></code></pre></td></tr></table></div></div><p>如上，业务pod使用了 pvc name为myclaim的pvc，做为卷存储，挂载到容器的/var/www/html</p><h2 id=pv和pvc设计目标>PV和PVC设计目标</h2><p>Kubernetes makes no guarantees at runtime that the underlying storage exists or is available. High availability is left to the storage provider.</p><p>Goals</p><ul><li>Allow administrators to describe available storage.（通过pv来定义存储资源）</li><li>Allow pod authors to discover and request persistent volumes to use with pods.（允许pod使用像使用pod的request资源一样使用存储pv）</li><li>Enforce security through access control lists and securing storage to the same namespace as the pod volume.（通过访问控制列表机制来保证存储使用安全）</li><li>Enforce quotas through admission control.（通过准入机制实现存储配额）</li><li>Enforce scheduler rules by resource counting.（基于资源数量调度，调度pvc->pv）</li><li>Ensure developers can rely on storage being available without being closely bound to a particular disk, server, network, or storage device.(通过抽象层设计，pod与具体的存储资源隔离)</li></ul><h2 id=persistentvolumecontroller分析>PersistentVolumeController分析</h2><h3 id=实例化>实例化</h3><p>volume manager controller 来管理persistentvolume
kubernetes\pkg\controller\volume\persistentvolume\</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-golang data-lang=golang><span class=c1>// NewController creates a new PersistentVolume controller
</span><span class=c1></span><span class=nx>controller</span> <span class=o>:=</span> <span class=o>&amp;</span><span class=nx>PersistentVolumeController</span><span class=p>{</span>
        <span class=nx>volumes</span><span class=p>:</span>                       <span class=nf>newPersistentVolumeOrderedIndex</span><span class=p>(),</span>
        <span class=nx>claims</span><span class=p>:</span>                        <span class=nx>cache</span><span class=p>.</span><span class=nf>NewStore</span><span class=p>(</span><span class=nx>cache</span><span class=p>.</span><span class=nx>DeletionHandlingMetaNamespaceKeyFunc</span><span class=p>),</span>
        <span class=nx>kubeClient</span><span class=p>:</span>                    <span class=nx>p</span><span class=p>.</span><span class=nx>KubeClient</span><span class=p>,</span>
        <span class=nx>eventRecorder</span><span class=p>:</span>                 <span class=nx>eventRecorder</span><span class=p>,</span>
        <span class=nx>runningOperations</span><span class=p>:</span>             <span class=nx>goroutinemap</span><span class=p>.</span><span class=nf>NewGoRoutineMap</span><span class=p>(</span><span class=kc>true</span> <span class=cm>/* exponentialBackOffOnError */</span><span class=p>),</span>
        <span class=nx>cloud</span><span class=p>:</span>                         <span class=nx>p</span><span class=p>.</span><span class=nx>Cloud</span><span class=p>,</span>
        <span class=nx>enableDynamicProvisioning</span><span class=p>:</span>     <span class=nx>p</span><span class=p>.</span><span class=nx>EnableDynamicProvisioning</span><span class=p>,</span>
        <span class=nx>clusterName</span><span class=p>:</span>                   <span class=nx>p</span><span class=p>.</span><span class=nx>ClusterName</span><span class=p>,</span>
        <span class=nx>createProvisionedPVRetryCount</span><span class=p>:</span> <span class=nx>createProvisionedPVRetryCount</span><span class=p>,</span>
        <span class=nx>createProvisionedPVInterval</span><span class=p>:</span>   <span class=nx>createProvisionedPVInterval</span><span class=p>,</span>
        <span class=nx>claimQueue</span><span class=p>:</span>                    <span class=nx>workqueue</span><span class=p>.</span><span class=nf>NewNamed</span><span class=p>(</span><span class=s>&#34;claims&#34;</span><span class=p>),</span>
        <span class=nx>volumeQueue</span><span class=p>:</span>                   <span class=nx>workqueue</span><span class=p>.</span><span class=nf>NewNamed</span><span class=p>(</span><span class=s>&#34;volumes&#34;</span><span class=p>),</span>
        <span class=nx>resyncPeriod</span><span class=p>:</span>                  <span class=nx>p</span><span class=p>.</span><span class=nx>SyncPeriod</span><span class=p>,</span>
        <span class=nx>operationTimestamps</span><span class=p>:</span>           <span class=nx>metrics</span><span class=p>.</span><span class=nf>NewOperationStartTimeCache</span><span class=p>(),</span>
    <span class=p>}</span>
</code></pre></td></tr></table></div></div><h3 id=pv-cache-构造>pv cache 构造</h3><p>newPersistentVolumeOrderedIndex -> persistentVolumeOrderedIndex
pv在cache中按AccessModes索引，并按存储量大小排序</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-golang data-lang=golang>
<span class=c1>// persistentVolumeOrderedIndex is a cache.Store that keeps persistent volumes
</span><span class=c1>// indexed by AccessModes and ordered by storage capacity.
</span><span class=c1></span><span class=kd>type</span> <span class=nx>persistentVolumeOrderedIndex</span> <span class=kd>struct</span> <span class=p>{</span>
    <span class=nx>store</span> <span class=nx>cache</span><span class=p>.</span><span class=nx>Indexer</span>
<span class=p>}</span>

<span class=kd>func</span> <span class=nf>newPersistentVolumeOrderedIndex</span><span class=p>()</span> <span class=nx>persistentVolumeOrderedIndex</span> <span class=p>{</span>
    <span class=k>return</span> <span class=nx>persistentVolumeOrderedIndex</span><span class=p>{</span><span class=nx>cache</span><span class=p>.</span><span class=nf>NewIndexer</span><span class=p>(</span><span class=nx>cache</span><span class=p>.</span><span class=nx>MetaNamespaceKeyFunc</span><span class=p>,</span> <span class=nx>cache</span><span class=p>.</span><span class=nx>Indexers</span><span class=p>{</span><span class=s>&#34;accessmodes&#34;</span><span class=p>:</span> <span class=nx>accessModesIndexFunc</span><span class=p>})}</span>
<span class=p>}</span>
</code></pre></td></tr></table></div></div><p>进行pv的同步操作</p><ul><li>如果 volume.Spec.ClaimRef == nil 说明pv没有被pvc绑定使用，直接更新pv：ctrl.updateVolumePhase(volume, v1.VolumeAvailable, &ldquo;")</li><li>volume.Spec.ClaimRef != nil 说明pv被pvc绑定使用，需要进行相应逻辑处理</li></ul><p>说明：pvc和 pv 是通过UID来进行关联标识：claim.UID != volume.Spec.ClaimRef.UID ?</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-golang data-lang=golang><span class=c1>// syncVolume is the main controller method to decide what to do with a volume.
</span><span class=c1>// It&#39;s invoked by appropriate cache.Controller callbacks when a volume is
</span><span class=c1>// created, updated or periodically synced. We do not differentiate between
</span><span class=c1>// these events.
</span><span class=c1></span><span class=kd>func</span> <span class=p>(</span><span class=nx>ctrl</span> <span class=o>*</span><span class=nx>PersistentVolumeController</span><span class=p>)</span> <span class=nf>syncVolume</span><span class=p>(</span><span class=nx>volume</span> <span class=o>*</span><span class=nx>v1</span><span class=p>.</span><span class=nx>PersistentVolume</span><span class=p>)</span> <span class=kt>error</span> <span class=p>{</span>
<span class=p>}</span>

</code></pre></td></tr></table></div></div><h3 id=为pvc匹配查找最佳pv>为pvc匹配查找最佳pv</h3><p>根据声明的pvc，在pv列表中匹配查找</p><ol><li>先按pvc要求的AccessModes，过滤出符合要求的pv候选列表</li><li>在pv候选列表中优选出最佳的pv</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-golang data-lang=golang>
<span class=c1>// findBestMatchForClaim is a convenience method that finds a volume by the claim&#39;s AccessModes and requests for Storage
</span><span class=c1></span><span class=kd>func</span> <span class=p>(</span><span class=nx>pvIndex</span> <span class=o>*</span><span class=nx>persistentVolumeOrderedIndex</span><span class=p>)</span> <span class=nf>findBestMatchForClaim</span><span class=p>(</span><span class=nx>claim</span> <span class=o>*</span><span class=nx>v1</span><span class=p>.</span><span class=nx>PersistentVolumeClaim</span><span class=p>,</span> <span class=nx>delayBinding</span> <span class=kt>bool</span><span class=p>)</span> <span class=p>(</span><span class=o>*</span><span class=nx>v1</span><span class=p>.</span><span class=nx>PersistentVolume</span><span class=p>,</span> <span class=kt>error</span><span class=p>)</span> <span class=p>{</span>
    <span class=k>return</span> <span class=nx>pvIndex</span><span class=p>.</span><span class=nf>findByClaim</span><span class=p>(</span><span class=nx>claim</span><span class=p>,</span> <span class=nx>delayBinding</span><span class=p>)</span>
<span class=p>}</span>



<span class=c1>// find returns the nearest PV from the ordered list or nil if a match is not found
</span><span class=c1></span><span class=kd>func</span> <span class=p>(</span><span class=nx>pvIndex</span> <span class=o>*</span><span class=nx>persistentVolumeOrderedIndex</span><span class=p>)</span> <span class=nf>findByClaim</span><span class=p>(</span><span class=nx>claim</span> <span class=o>*</span><span class=nx>v1</span><span class=p>.</span><span class=nx>PersistentVolumeClaim</span><span class=p>,</span> <span class=nx>delayBinding</span> <span class=kt>bool</span><span class=p>)</span> <span class=p>(</span><span class=o>*</span><span class=nx>v1</span><span class=p>.</span><span class=nx>PersistentVolume</span><span class=p>,</span> <span class=kt>error</span><span class=p>)</span> <span class=p>{</span>
    <span class=c1>// PVs are indexed by their access modes to allow easier searching.  Each
</span><span class=c1></span>    <span class=c1>// index is the string representation of a set of access modes. There is a
</span><span class=c1></span>    <span class=c1>// finite number of possible sets and PVs will only be indexed in one of
</span><span class=c1></span>    <span class=c1>// them (whichever index matches the PV&#39;s modes).
</span><span class=c1></span>    <span class=c1>//
</span><span class=c1></span>    <span class=c1>// A request for resources will always specify its desired access modes.
</span><span class=c1></span>    <span class=c1>// Any matching PV must have at least that number of access modes, but it
</span><span class=c1></span>    <span class=c1>// can have more.  For example, a user asks for ReadWriteOnce but a GCEPD
</span><span class=c1></span>    <span class=c1>// is available, which is ReadWriteOnce+ReadOnlyMany.
</span><span class=c1></span>    <span class=c1>//
</span><span class=c1></span>    <span class=c1>// Searches are performed against a set of access modes, so we can attempt
</span><span class=c1></span>    <span class=c1>// not only the exact matching modes but also potential matches (the GCEPD
</span><span class=c1></span>    <span class=c1>// example above).
</span><span class=c1></span>    <span class=nx>allPossibleModes</span> <span class=o>:=</span> <span class=nx>pvIndex</span><span class=p>.</span><span class=nf>allPossibleMatchingAccessModes</span><span class=p>(</span><span class=nx>claim</span><span class=p>.</span><span class=nx>Spec</span><span class=p>.</span><span class=nx>AccessModes</span><span class=p>)</span>

    <span class=k>for</span> <span class=nx>_</span><span class=p>,</span> <span class=nx>modes</span> <span class=o>:=</span> <span class=k>range</span> <span class=nx>allPossibleModes</span> <span class=p>{</span>
        <span class=nx>volumes</span><span class=p>,</span> <span class=nx>err</span> <span class=o>:=</span> <span class=nx>pvIndex</span><span class=p>.</span><span class=nf>listByAccessModes</span><span class=p>(</span><span class=nx>modes</span><span class=p>)</span>
        <span class=k>if</span> <span class=nx>err</span> <span class=o>!=</span> <span class=kc>nil</span> <span class=p>{</span>
            <span class=k>return</span> <span class=kc>nil</span><span class=p>,</span> <span class=nx>err</span>
        <span class=p>}</span>

        <span class=nx>bestVol</span><span class=p>,</span> <span class=nx>err</span> <span class=o>:=</span> <span class=nx>pvutil</span><span class=p>.</span><span class=nf>FindMatchingVolume</span><span class=p>(</span><span class=nx>claim</span><span class=p>,</span> <span class=nx>volumes</span><span class=p>,</span> <span class=kc>nil</span> <span class=cm>/* node for topology binding*/</span><span class=p>,</span> <span class=kc>nil</span> <span class=cm>/* exclusion map */</span><span class=p>,</span> <span class=nx>delayBinding</span><span class=p>)</span>
        <span class=k>if</span> <span class=nx>err</span> <span class=o>!=</span> <span class=kc>nil</span> <span class=p>{</span>
            <span class=k>return</span> <span class=kc>nil</span><span class=p>,</span> <span class=nx>err</span>
        <span class=p>}</span>

        <span class=k>if</span> <span class=nx>bestVol</span> <span class=o>!=</span> <span class=kc>nil</span> <span class=p>{</span>
            <span class=k>return</span> <span class=nx>bestVol</span><span class=p>,</span> <span class=kc>nil</span>
        <span class=p>}</span>
    <span class=p>}</span>
    <span class=k>return</span> <span class=kc>nil</span><span class=p>,</span> <span class=kc>nil</span>
<span class=p>}</span>

</code></pre></td></tr></table></div></div><p>优选算法函数如下，该函数会被PV controller 和 scheduler 使用</p><ul><li>参数delayBinding 只在PV controller流程为true</li><li>参数node和excludedVolumes 只在scheduler流程设置</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-golang data-lang=golang><span class=c1>// FindMatchingVolume goes through the list of volumes to find the best matching volume
</span><span class=c1>// for the claim.
</span><span class=c1>//
</span><span class=c1>// This function is used by both the PV controller and scheduler.
</span><span class=c1>//
</span><span class=c1>// delayBinding is true only in the PV controller path.  When set, prebound PVs are still returned
</span><span class=c1>// as a match for the claim, but unbound PVs are skipped.
</span><span class=c1>//
</span><span class=c1>// node is set only in the scheduler path. When set, the PV node affinity is checked against
</span><span class=c1>// the node&#39;s labels.
</span><span class=c1>//
</span><span class=c1>// excludedVolumes is only used in the scheduler path, and is needed for evaluating multiple
</span><span class=c1>// unbound PVCs for a single Pod at one time.  As each PVC finds a matching PV, the chosen
</span><span class=c1>// PV needs to be excluded from future matching.
</span><span class=c1></span><span class=kd>func</span> <span class=nf>FindMatchingVolume</span><span class=p>(</span>
    <span class=nx>claim</span> <span class=o>*</span><span class=nx>v1</span><span class=p>.</span><span class=nx>PersistentVolumeClaim</span><span class=p>,</span>
    <span class=nx>volumes</span> <span class=p>[]</span><span class=o>*</span><span class=nx>v1</span><span class=p>.</span><span class=nx>PersistentVolume</span><span class=p>,</span>
    <span class=nx>node</span> <span class=o>*</span><span class=nx>v1</span><span class=p>.</span><span class=nx>Node</span><span class=p>,</span>
    <span class=nx>excludedVolumes</span> <span class=kd>map</span><span class=p>[</span><span class=kt>string</span><span class=p>]</span><span class=o>*</span><span class=nx>v1</span><span class=p>.</span><span class=nx>PersistentVolume</span><span class=p>,</span>
    <span class=nx>delayBinding</span> <span class=kt>bool</span><span class=p>)</span> <span class=p>(</span><span class=o>*</span><span class=nx>v1</span><span class=p>.</span><span class=nx>PersistentVolume</span><span class=p>,</span> <span class=kt>error</span><span class=p>)</span> <span class=p>{</span>

    <span class=p>}</span>

</code></pre></td></tr></table></div></div><h2 id=matching-and-binding-pvc-pv>Matching and binding PVC->PV</h2><p>PersistentVolumeClaimBinder尝试查找与用户请求最接近的可用卷。如果存在，则通过将pv上的引用绑定到pvc。如果找不到合适的匹配，请求可能无法满足。</p><p>claim(PVC)必须请求访问模式和存储容量。这是因为内部PV是按其AccessModes索引的，目标PV在某种程度上是按其容量排序的。pvc声明可以请求以下多个属性中的一个来更好地匹配PV：卷名称、选择器和卷类(当前实现为注释)。</p><p>PV可以定义一个ClaimRef，它会对PVC的匹配产生很大的影响(但不是绝对的保证)。PV还可以定义标签、注释和卷类(当前作为注释实现)以更好地针对目标PVC。</p><p>PVC->PV匹配算法说明：</p><p>As of Kubernetes version 1.4, the following algorithm describes in more details how a claim is matched to a PV:</p><ol><li><p>Only PVs with accessModes equal to or greater than the claim&rsquo;s requested accessModes are considered. &ldquo;Greater&rdquo; here means that the PV has defined more modes than needed by the claim, but it also defines the mode requested by the claim.</p></li><li><p>The potential PVs above are considered in order of the closest access mode match, with the best case being an exact match, and a worse case being more modes than requested by the claim.</p></li><li><p>Each PV above is processed. If the PV has a claimRef matching the claim, and the PV&rsquo;s capacity is not less than the storage being requested by the claim then this PV will bind to the claim. Done.</p></li><li><p>Otherwise, if the PV has the &ldquo;volume.alpha.kubernetes.io/storage-class&rdquo; annotation defined then it is skipped and will be handled by Dynamic Provisioning.</p></li><li><p>Otherwise, if the PV has a claimRef defined, which can specify a different claim or simply be a placeholder, then the PV is skipped. 这点说明了 PV和PVC之间的关系是1对1</p></li><li><p>Otherwise, if the claim is using a selector but it does not match the PV&rsquo;s labels (if any) then the PV is skipped. But, even if a claim has selectors which match a PV that does not guarantee a match since capacities may differ.</p></li><li><p>Otherwise, if the PV&rsquo;s &ldquo;volume.beta.kubernetes.io/storage-class&rdquo; annotation (which is a placeholder for a volume class) does not match the claim&rsquo;s annotation (same placeholder) then the PV is skipped. If the annotations for the PV and PVC are empty they are treated as being equal.</p></li><li><p>Otherwise, what remains is a list of PVs that may match the claim. Within this list of remaining PVs, the PV with the smallest capacity that is also equal to or greater than the claim&rsquo;s requested storage is the matching PV and will be bound to the claim. Done. In the case of two or more PVCs matching all of the above criteria, the first PV (remember the PV order is based on accessModes) is the winner. 候选PV列表中最小资源满足的PV为最佳优选结果</p></li></ol><blockquote><p>Note: if no PV matches the claim and the claim defines a StorageClass (or a default StorageClass has been defined) then a volume will be dynamically provisioned.</p></blockquote><h2 id=测试nfs-pv-pvc>测试NFS-PV-PVC</h2><p>下面的示例演示如何从单个nfs server的POD RC控制器导出NFS共享，并将其导入web的两个RC控制器。</p><h3 id=nfs-server>nfs server</h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-dockerfile data-lang=dockerfile><span class=c># Copyright 2016 The Kubernetes Authors.</span><span class=err>
</span><span class=err></span><span class=c>#</span><span class=err>
</span><span class=err></span><span class=c># Licensed under the Apache License, Version 2.0 (the &#34;License&#34;);</span><span class=err>
</span><span class=err></span><span class=c># you may not use this file except in compliance with the License.</span><span class=err>
</span><span class=err></span><span class=c># You may obtain a copy of the License at</span><span class=err>
</span><span class=err></span><span class=c>#</span><span class=err>
</span><span class=err></span><span class=c>#     http://www.apache.org/licenses/LICENSE-2.0</span><span class=err>
</span><span class=err></span><span class=c>#</span><span class=err>
</span><span class=err></span><span class=c># Unless required by applicable law or agreed to in writing, software</span><span class=err>
</span><span class=err></span><span class=c># distributed under the License is distributed on an &#34;AS IS&#34; BASIS,</span><span class=err>
</span><span class=err></span><span class=c># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><span class=err>
</span><span class=err></span><span class=c># See the License for the specific language governing permissions and</span><span class=err>
</span><span class=err></span><span class=c># limitations under the License.</span><span class=err>
</span><span class=err>
</span><span class=err></span><span class=k>FROM</span><span class=s> centos</span><span class=err>
</span><span class=err></span><span class=k>RUN</span> yum -y install /usr/bin/ps nfs-utils <span class=o>&amp;&amp;</span> yum clean all<span class=err>
</span><span class=err></span><span class=k>RUN</span> mkdir -p /exports<span class=err>
</span><span class=err></span><span class=k>ADD</span> run_nfs.sh /usr/local/bin/<span class=err>
</span><span class=err></span><span class=k>ADD</span> index.html /tmp/index.html<span class=err>
</span><span class=err></span><span class=k>RUN</span> chmod <span class=m>644</span> /tmp/index.html<span class=err>
</span><span class=err>
</span><span class=err></span><span class=c># expose mountd 20048/tcp and nfsd 2049/tcp and rpcbind 111/tcp</span><span class=err>
</span><span class=err></span><span class=k>EXPOSE</span><span class=s> 2049/tcp 20048/tcp 111/tcp 111/udp</span><span class=err>
</span><span class=err>
</span><span class=err></span><span class=k>ENTRYPOINT</span> <span class=p>[</span><span class=s2>&#34;/usr/local/bin/run_nfs.sh&#34;</span><span class=p>,</span> <span class=s2>&#34;/exports&#34;</span><span class=p>]</span><span class=err>
</span><span class=err>
</span><span class=err>
</span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-shell data-lang=shell><span class=c1># 制作镜像</span>
docker build -t k8s.gcr.io/volume-nfs:0.8 .

docker save k8s.gcr.io/volume-nfs:0.8 -o volume-nfs-img.tar
</code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-shell data-lang=shell><span class=c1># 在测试环境中导出镜像</span>
docker load -i volume-nfs-img.tar
</code></pre></td></tr></table></div></div><h3 id=nfs-server-part>NFS server part</h3><ul><li>把nfs测试配置脚本文件examples/staging/volumes/nfs拷贝到测试环境中</li><li>修改下测试镜像名称：如busybox和nginx</li><li>按需要， 创建 gce-pv</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-shell data-lang=shell><span class=c1># If you are on GCE, create a GCE PD-based PVC:</span>
<span class=c1># kubectl create -f examples/staging/volumes/nfs/provisioner/nfs-server-gce-pv.yaml</span>
<span class=c1># kubectl create -f nfs/provisioner/nfs-server-gce-pv.yaml</span>
</code></pre></td></tr></table></div></div><p>test pv和 pvc</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-shell data-lang=shell><span class=c1># test pv</span>
kubectl create -f nfs/test/pv0001.yaml

<span class=c1># test pvc</span>
kubectl create -f nfs/test/pvc-pv0001.yaml
</code></pre></td></tr></table></div></div><ul><li>创建 NFS server and service</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-shell data-lang=shell><span class=c1>#kubectl create -f examples/staging/volumes/nfs/nfs-server-rc.yaml</span>
<span class=c1>#kubectl create -f examples/staging/volumes/nfs/nfs-server-service.yaml</span>
kubectl create -f nfs/custom-nfs-server-rc.yaml
kubectl create -f nfs/nfs-server-service.yaml
</code></pre></td></tr></table></div></div><p>说明创建pod时，其使用的pvc必须为bound状态才能进行调度</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash>Tolerations:     node.kubernetes.io/not-ready:NoExecute <span class=nv>op</span><span class=o>=</span>Exists <span class=k>for</span> 300s
                 node.kubernetes.io/unreachable:NoExecute <span class=nv>op</span><span class=o>=</span>Exists <span class=k>for</span> 300s
Events:
  Type     Reason            Age   From               Message
  ----     ------            ----  ----               -------
  Warning  FailedScheduling  29s   default-scheduler  0/1 nodes are available: <span class=m>1</span> persistentvolumeclaim <span class=s2>&#34;nfs-pv-provisioning-demo&#34;</span> not found.
  Warning  FailedScheduling  29s   default-scheduler  0/1 nodes are available: <span class=m>1</span> persistentvolumeclaim <span class=s2>&#34;nfs-pv-provisioning-demo&#34;</span> not found.

</code></pre></td></tr></table></div></div><ul><li>创建基于NFS的pv和pvc
检查下nfs-server</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-shell data-lang=shell>
kubectl describe services nfs-server

</code></pre></td></tr></table></div></div><p>nfs的服务端口</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=o>[</span>root@node131 k8s_pv_pvc<span class=o>]</span><span class=c1># kubectl describe services nfs-server</span>
Name:              nfs-server
Namespace:         default
Labels:            &lt;none&gt;
Annotations:       &lt;none&gt;
Selector:          <span class=nv>role</span><span class=o>=</span>nfs-server
Type:              ClusterIP
IP Families:       &lt;none&gt;
IP:                10.233.63.192
IPs:               10.233.63.192
Port:              nfs  2049/TCP
TargetPort:        2049/TCP
Endpoints:         10.233.124.46:2049
Port:              mountd  20048/TCP
TargetPort:        20048/TCP
Endpoints:         10.233.124.46:20048
Port:              rpcbind  111/TCP
TargetPort:        111/TCP
Endpoints:         10.233.124.46:111
Session Affinity:  None
Events:            &lt;none&gt;

</code></pre></td></tr></table></div></div><p>然后再创建nfs的pv和pvc</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-shell data-lang=shell>
<span class=c1>#kubectl create -f examples/staging/volumes/nfs/nfs-pv.yaml</span>
<span class=c1>#kubectl create -f examples/staging/volumes/nfs/nfs-pvc.yaml</span>

kubectl create -f nfs/custom-nfs-pv.yaml
kubectl create -f nfs/custom-nfs-pvc.yaml
</code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=o>[</span>root@node131 k8s_pv_pvc<span class=o>]</span><span class=c1># kubectl create -f nfs/nfs-pv.yaml</span>
persistentvolume/nfs created
<span class=o>[</span>root@node131 k8s_pv_pvc<span class=o>]</span><span class=c1># kubectl get pv</span>
NAME   CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   REASON   AGE
nfs    1Mi        RWX            Retain           Available                                   6s

<span class=o>[</span>root@node131 k8s_pv_pvc<span class=o>]</span><span class=c1># kubectl describe pv nfs</span>
Name:            nfs
Labels:          &lt;none&gt;
Annotations:     &lt;none&gt;
Finalizers:      <span class=o>[</span>kubernetes.io/pv-protection<span class=o>]</span>
StorageClass:
Status:          Available
Claim:
Reclaim Policy:  Retain
Access Modes:    RWX
VolumeMode:      Filesystem
Capacity:        1Mi
Node Affinity:   &lt;none&gt;
Message:
Source:
    Type:      NFS <span class=o>(</span>an NFS mount that lasts the lifetime of a pod<span class=o>)</span>
    Server:    nfs-server.default.svc.cluster.local
    Path:      /tmp/data
    ReadOnly:  <span class=nb>false</span>
Events:        &lt;none&gt;
<span class=o>[</span>root@node131 k8s_pv_pvc<span class=o>]</span><span class=c1>#</span>




<span class=o>[</span>root@node131 k8s_pv_pvc<span class=o>]</span><span class=c1># kubectl create -f nfs/nfs-pvc.yaml</span>
persistentvolumeclaim/nfs created
<span class=o>[</span>root@node131 k8s_pv_pvc<span class=o>]</span><span class=c1>#</span>
<span class=o>[</span>root@node131 k8s_pv_pvc<span class=o>]</span><span class=c1>#</span>
<span class=o>[</span>root@node131 k8s_pv_pvc<span class=o>]</span><span class=c1># kubectl get pv</span>
NAME   CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM         STORAGECLASS   REASON   AGE
nfs    1Mi        RWX            Retain           Bound    default/nfs                           114s
<span class=o>[</span>root@node131 k8s_pv_pvc<span class=o>]</span><span class=c1>#</span>
<span class=o>[</span>root@node131 k8s_pv_pvc<span class=o>]</span><span class=c1># kubectl get pvc</span>
NAME   STATUS   VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   AGE
nfs    Bound    nfs      1Mi        RWX                           16s
<span class=o>[</span>root@node131 k8s_pv_pvc<span class=o>]</span><span class=c1>#</span>
<span class=o>[</span>root@node131 k8s_pv_pvc<span class=o>]</span><span class=c1>#</span>

</code></pre></td></tr></table></div></div><p>此时再查看pv和pvc的信息，能够看到注解信息有变化，状态为Status: Bound</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=o>[</span>root@node131 k8s_pv_pvc<span class=o>]</span><span class=c1># kubectl describe pv nfs</span>
Name:            nfs
Labels:          &lt;none&gt;
Annotations:     pv.kubernetes.io/bound-by-controller: yes
Finalizers:      <span class=o>[</span>kubernetes.io/pv-protection<span class=o>]</span>
StorageClass:
Status:          Bound
Claim:           default/nfs
Reclaim Policy:  Retain
Access Modes:    RWX
VolumeMode:      Filesystem
Capacity:        1Mi
Node Affinity:   &lt;none&gt;
Message:
Source:
    Type:      NFS <span class=o>(</span>an NFS mount that lasts the lifetime of a pod<span class=o>)</span>
    Server:    nfs-server.default.svc.cluster.local
    Path:      /tmp/data
    ReadOnly:  <span class=nb>false</span>
Events:        &lt;none&gt;
<span class=o>[</span>root@node131 k8s_pv_pvc<span class=o>]</span><span class=c1>#</span>
<span class=o>[</span>root@node131 k8s_pv_pvc<span class=o>]</span><span class=c1>#</span>
<span class=o>[</span>root@node131 k8s_pv_pvc<span class=o>]</span><span class=c1># kubectl describe pvc nfs</span>
Name:          nfs
Namespace:     default
StorageClass:
Status:        Bound
Volume:        nfs
Labels:        &lt;none&gt;
Annotations:   pv.kubernetes.io/bind-completed: yes
               pv.kubernetes.io/bound-by-controller: yes
Finalizers:    <span class=o>[</span>kubernetes.io/pvc-protection<span class=o>]</span>
Capacity:      1Mi
Access Modes:  RWX
VolumeMode:    Filesystem
Used By:       &lt;none&gt;
Events:        &lt;none&gt;
<span class=o>[</span>root@node131 k8s_pv_pvc<span class=o>]</span><span class=c1>#</span>

</code></pre></td></tr></table></div></div><ul><li>使用后端程序使用上面绑定好的nfs pvc，更新nfs的数据目录，即html页面</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-shell data-lang=shell><span class=c1>#kubectl create -f examples/staging/volumes/nfs/nfs-busybox-rc.yaml</span>
kubectl create -f nfs/custom-nfs-busybox-rc.yaml

</code></pre></td></tr></table></div></div><p>其信息显示如下：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=o>[</span>root@node131 nfs<span class=o>]</span><span class=c1># kubectl get po -A</span>
NAMESPACE     NAME                                       READY   STATUS    RESTARTS   AGE
default       nfs-busybox-mntdb                          1/1     Running   <span class=m>0</span>          35s
default       nfs-busybox-r76ml                          1/1     Running   <span class=m>0</span>          35s
default       nfs-server-p6p4n                           1/1     Running   <span class=m>1</span>          134m
kube-system   calico-kube-controllers-65b86747bd-c4qsp   1/1     Running   <span class=m>10</span>         41d
kube-system   calico-node-lglh4                          1/1     Running   <span class=m>11</span>         41d
kube-system   coredns-8677555d68-flqh4                   1/1     Running   <span class=m>1</span>          90m
kube-system   kube-apiserver-node131                     1/1     Running   <span class=m>10</span>         41d
kube-system   kube-controller-manager-node131            1/1     Running   <span class=m>10</span>         41d
kube-system   kube-proxy-mktp9                           1/1     Running   <span class=m>10</span>         41d
kube-system   kube-scheduler-node131                     1/1     Running   <span class=m>10</span>         41d
kube-system   nodelocaldns-lfjzs                         1/1     Running   <span class=m>10</span>         41d
<span class=o>[</span>root@node131 nfs<span class=o>]</span><span class=c1>#</span>




<span class=o>[</span>root@node131 nfs<span class=o>]</span><span class=c1># cat /tmp/data/index.html</span>
Mon Feb  <span class=m>1</span> 09:59:49 UTC <span class=m>2021</span>
nfs-busybox-9td8j
<span class=o>[</span>root@node131 nfs<span class=o>]</span><span class=c1># cat /tmp/data/index.html</span>
Mon Feb  <span class=m>1</span> 09:59:49 UTC <span class=m>2021</span>
nfs-busybox-9td8j
<span class=o>[</span>root@node131 nfs<span class=o>]</span><span class=c1>#</span>
<span class=o>[</span>root@node131 nfs<span class=o>]</span><span class=c1>#</span>
<span class=o>[</span>root@node131 nfs<span class=o>]</span><span class=c1>#</span>
<span class=o>[</span>root@node131 nfs<span class=o>]</span><span class=c1>#</span>
<span class=o>[</span>root@node131 nfs<span class=o>]</span><span class=c1># cat /tmp/data/index.html</span>
Mon Feb  <span class=m>1</span> 09:59:57 UTC <span class=m>2021</span>
nfs-busybox-9td8j
<span class=o>[</span>root@node131 nfs<span class=o>]</span><span class=c1>#</span>


<span class=o>[</span>root@node131 nfs<span class=o>]</span><span class=c1># kubectl exec -ndefault       nfs-busybox-r76ml -- cat /mnt/index.html</span>
Mon Feb  <span class=m>1</span> 10:17:58 UTC <span class=m>2021</span>
nfs-busybox-mntdb
<span class=o>[</span>root@node131 nfs<span class=o>]</span><span class=c1>#</span>



</code></pre></td></tr></table></div></div><p>每10s左右会更新web页面。这个busybox执行的是存储写操作。。。
多个busybox的运行pod表示多实例写操作</p><ul><li>启动web server（nginx）</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-shell data-lang=shell><span class=c1>#kubectl create -f examples/staging/volumes/nfs/nfs-web-rc.yaml</span>
<span class=c1>#kubectl create -f examples/staging/volumes/nfs/nfs-web-service.yaml</span>

kubectl create -f nfs/nfs-web-rc.yaml
kubectl create -f nfs/nfs-web-service.yaml

</code></pre></td></tr></table></div></div><p>web服务已运行，查看web服务的html页面</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash>
<span class=o>[</span>root@node131 nfs<span class=o>]</span><span class=c1># kubectl get po -A</span>
NAMESPACE     NAME                                       READY   STATUS    RESTARTS   AGE
default       nfs-busybox-mntdb                          1/1     Running   <span class=m>0</span>          35s
default       nfs-busybox-r76ml                          1/1     Running   <span class=m>0</span>          35s
default       nfs-server-p6p4n                           1/1     Running   <span class=m>1</span>          134m
default       nfs-web-dhmst                              1/1     Running   <span class=m>0</span>          8m19s
default       nfs-web-lxlcr                              1/1     Running   <span class=m>0</span>          8m19s
kube-system   calico-kube-controllers-65b86747bd-c4qsp   1/1     Running   <span class=m>10</span>         41d
kube-system   calico-node-lglh4                          1/1     Running   <span class=m>11</span>         41d
kube-system   coredns-8677555d68-flqh4                   1/1     Running   <span class=m>1</span>          90m
kube-system   kube-apiserver-node131                     1/1     Running   <span class=m>10</span>         41d
kube-system   kube-controller-manager-node131            1/1     Running   <span class=m>10</span>         41d
kube-system   kube-proxy-mktp9                           1/1     Running   <span class=m>10</span>         41d
kube-system   kube-scheduler-node131                     1/1     Running   <span class=m>10</span>         41d
kube-system   nodelocaldns-lfjzs                         1/1     Running   <span class=m>10</span>         41d
<span class=o>[</span>root@node131 nfs<span class=o>]</span><span class=c1>#</span>
<span class=o>[</span>root@node131 nfs<span class=o>]</span><span class=c1>#</span>



<span class=o>[</span>root@node131 nfs<span class=o>]</span><span class=c1># kubectl get svc</span>
NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT<span class=o>(</span>S<span class=o>)</span>                      AGE
kubernetes   ClusterIP   10.233.0.1      &lt;none&gt;        443/TCP                      41d
nfs-server   ClusterIP   10.233.63.192   &lt;none&gt;        2049/TCP,20048/TCP,111/TCP   140m
nfs-web      ClusterIP   10.233.63.218   &lt;none&gt;        80/TCP                       15m
<span class=o>[</span>root@node131 nfs<span class=o>]</span><span class=c1>#</span>
<span class=o>[</span>root@node131 nfs<span class=o>]</span><span class=c1>#</span>

<span class=o>[</span>root@node131 nfs<span class=o>]</span><span class=c1># kubectl exec nfs-web-dhmst -- cat /usr/share/nginx/html/index.html</span>
Mon Feb  <span class=m>1</span> 10:06:54 UTC <span class=m>2021</span>
nfs-busybox-9td8j
<span class=o>[</span>root@node131 nfs<span class=o>]</span><span class=c1>#</span>


</code></pre></td></tr></table></div></div><p>在busybox的pod中，http访问web服务，查看页面</p><p>直接访问web服务域名</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-shell data-lang=shell>kubectl <span class=nb>exec</span> -ndefault       nfs-busybox-mntdb -- wget -qO- http://nfs-web
</code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=o>[</span>root@node131 nfs<span class=o>]</span><span class=c1>#</span>
<span class=o>[</span>root@node131 nfs<span class=o>]</span><span class=c1># kubectl exec -ndefault       nfs-busybox-mntdb -- wget -qO- http://nfs-web</span>
Mon Feb  <span class=m>1</span> 10:24:37 UTC <span class=m>2021</span>
nfs-busybox-mntdb
<span class=o>[</span>root@node131 nfs<span class=o>]</span><span class=c1>#</span>
<span class=o>[</span>root@node131 nfs<span class=o>]</span><span class=c1>#</span>
<span class=o>[</span>root@node131 nfs<span class=o>]</span><span class=c1>#</span>
<span class=o>[</span>root@node131 nfs<span class=o>]</span><span class=c1># kubectl exec -ndefault       nfs-busybox-mntdb -- wget -qO- http://nfs-web</span>
Mon Feb  <span class=m>1</span> 10:24:41 UTC <span class=m>2021</span>
nfs-busybox-r76ml
<span class=o>[</span>root@node131 nfs<span class=o>]</span><span class=c1>#</span>


</code></pre></td></tr></table></div></div><h3 id=测试的pv和pvc信息>测试的pv和pvc信息</h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-shell data-lang=shell><span class=o>[</span>root@node131 ~<span class=o>]</span><span class=c1># kubectl describe pv</span>
Name:            nfs
Labels:          &lt;none&gt;
Annotations:     pv.kubernetes.io/bound-by-controller: yes
Finalizers:      <span class=o>[</span>kubernetes.io/pv-protection<span class=o>]</span>
StorageClass:
Status:          Bound
Claim:           default/nfs
Reclaim Policy:  Retain
Access Modes:    RWX
VolumeMode:      Filesystem
Capacity:        1Mi
Node Affinity:   &lt;none&gt;
Message:
Source:
    Type:      NFS <span class=o>(</span>an NFS mount that lasts the lifetime of a pod<span class=o>)</span>
    Server:    10.233.16.102
    Path:      /exports
    ReadOnly:  <span class=nb>false</span>
Events:        &lt;none&gt;
<span class=o>[</span>root@node131 ~<span class=o>]</span><span class=c1>#</span>
<span class=o>[</span>root@node131 ~<span class=o>]</span><span class=c1>#</span>
<span class=o>[</span>root@node131 ~<span class=o>]</span><span class=c1># kubectl describe pvc</span>
Name:          nfs
Namespace:     default
StorageClass:
Status:        Bound
Volume:        nfs
Labels:        &lt;none&gt;
Annotations:   pv.kubernetes.io/bind-completed: yes
               pv.kubernetes.io/bound-by-controller: yes
Finalizers:    <span class=o>[</span>kubernetes.io/pvc-protection<span class=o>]</span>
Capacity:      1Mi
Access Modes:  RWX
VolumeMode:    Filesystem
Used By:       nfs-busybox-b8wdw
               nfs-busybox-hvc8w
               nfs-web-7bnhj
               nfs-web-mxpx9
Events:        &lt;none&gt;


</code></pre></td></tr></table></div></div><h3 id=部署>部署</h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-shell data-lang=shell><span class=c1># create nfs server</span>
kubectl create -f nfs/custom-nfs-server-rc.yaml
kubectl create -f nfs/nfs-server-service.yaml


<span class=c1># create nfs pv pvc</span>
kubectl create -f nfs/custom-nfs-pv.yaml
kubectl create -f nfs/custom-nfs-pvc.yaml


<span class=c1># create busybox write</span>
kubectl create -f nfs/custom-nfs-busybox-rc.yaml

<span class=c1># create web read</span>
kubectl create -f nfs/nfs-web-rc.yaml
kubectl create -f nfs/nfs-web-service.yaml

</code></pre></td></tr></table></div></div><h3 id=卸载>卸载</h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-shell data-lang=shell>
<span class=c1># remove web read</span>
kubectl delete -f nfs/nfs-web-service.yaml
kubectl delete -f nfs/nfs-web-rc.yaml

<span class=c1># remove busybox write</span>
kubectl delete -f nfs/custom-nfs-busybox-rc.yaml
<span class=c1># remove nfs pv pvc</span>
kubectl delete -f nfs/nfs-pvc.yaml
kubectl delete -f nfs/custom-nfs-pv.yaml

<span class=c1># remove nfs server</span>
kubectl delete -f nfs/nfs-server-service.yaml
kubectl delete -f nfs/custom-nfs-server-rc.yaml


</code></pre></td></tr></table></div></div><h2 id=问题>问题</h2><p>启动测试pod，进行mount时失败</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash>
Events:
  Type     Reason       Age                From               Message
  ----     ------       ----               ----               -------
  Normal   Scheduled    26s                default-scheduler  Successfully assigned default/nfs-busybox-jwshl to node131
  Warning  FailedMount  11s <span class=o>(</span>x6 over 27s<span class=o>)</span>  kubelet            MountVolume.SetUp failed <span class=k>for</span> volume <span class=s2>&#34;nfs&#34;</span> : mount failed: <span class=nb>exit</span> status <span class=m>32</span>
Mounting command: mount
Mounting arguments: -t nfs nfs-server.default.svc.cluster.local:/tmp/data /var/lib/kubelet/pods/d4ca8ca9-e1c8-4610-8a74-f0fdea827fee/volumes/kubernetes.io~nfs/nfs
Output: mount: 文件系统类型错误、选项错误、nfs-server.default.svc.cluster.local:/tmp/data 上有坏超级块、
       缺少代码页或助手程序，或其他错误
       <span class=o>(</span>对某些文件系统<span class=o>(</span>如 nfs、cifs<span class=o>)</span> 您可能需要
       一款 /sbin/mount.&lt;类型&gt; 助手程序<span class=o>)</span>

       有些情况下在 syslog 中可以找到一些有用信息- 请尝试
       dmesg <span class=p>|</span> tail  这样的命令看看。

</code></pre></td></tr></table></div></div><p>首先检查 内核是否支持nfs文件系统格式，方法如下</p><p>cat /proc/filesystems 如果能够看到 nfs 或者nfs4字样就说明内核支持nfs格式的文件系统，否则需要重新编译新的支持nfs文件系统的内核。</p><p>如果检查内核支持nfs格式的文件系统后，检查mount.nfs是否安装：</p><p>ls /sbin/mount.* 看是否有 mount.nfs 或者 mount.nfs4 如果没有需要安装 nfs_utils</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-shell data-lang=shell>ls /sbin/mount.*
</code></pre></td></tr></table></div></div><p>yum install nfs-utils (redhat系列)</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-shell data-lang=shell>yum install -y nfs-utils 
</code></pre></td></tr></table></div></div><p>apt-get install common(ubuntu系列)</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-shell data-lang=shell>apt-get install nfs-common
</code></pre></td></tr></table></div></div><p>挂载域名无法解析，使用ip地址标识</p><h3 id=output-mountnfs-protocol-not-supported>Output: mount.nfs: Protocol not supported</h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>Events:
  Type     Reason       Age                From               Message
  ----     ------       ----               ----               -------
  Normal   Scheduled    28s                default-scheduler  Successfully assigned default/nfs-busybox-k6dpc to node131
  Warning  FailedMount  11s (x6 over 27s)  kubelet            MountVolume.SetUp failed for volume &#34;nfs&#34; : mount failed: exit status 32
Mounting command: mount
Mounting arguments: -t nfs 10.233.124.49:/tmp/data /var/lib/kubelet/pods/e5932fde-fe05-4612-b29d-333f48b03338/volumes/kubernetes.io~nfs/nfs
Output: mount.nfs: Protocol not supported
[root@node131 nfs]#


</code></pre></td></tr></table></div></div><p><a href=https://stackoverflow.com/questions/35650935/output-mount-nfs-requested-nfs-version-or-transport-protocol-is-not-supported>https://stackoverflow.com/questions/35650935/output-mount-nfs-requested-nfs-version-or-transport-protocol-is-not-supported</a></p><h3 id=访问挂载路径服务端access-denied>访问挂载路径，服务端access denied</h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>
Events:
  Type     Reason       Age               From               Message
  ----     ------       ----              ----               -------
  Normal   Scheduled    33s               default-scheduler  Successfully assigned default/nfs-busybox-4ht5m to node131
  Warning  FailedMount  1s (x7 over 34s)  kubelet            MountVolume.SetUp failed for volume &#34;nfs&#34; : mount failed: exit status 32
Mounting command: mount
Mounting arguments: -t nfs 10.233.124.49:/ /var/lib/kubelet/pods/bd34361c-4883-47a2-9e70-08772437e341/volumes/kubernetes.io~nfs/nfs
Output: mount.nfs: access denied by server while mounting 10.233.124.49:/
[root@node131 nfs]#
</code></pre></td></tr></table></div></div><p>原因挂载路径错误</p><p>pv配置的挂载路径path需跟nfs服务定义的路径一致。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-yaml data-lang=yaml><span class=w>
</span><span class=w></span><span class=nt>nfs</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=c>#server: nfs-server.default.svc.cluster.local</span><span class=w>
</span><span class=w>    </span><span class=nt>server</span><span class=p>:</span><span class=w> </span><span class=m>10.233.124.49</span><span class=w>
</span><span class=w>    </span><span class=nt>path</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;/exports&#34;</span><span class=w>
</span><span class=w>
</span></code></pre></td></tr></table></div></div><h2 id=附录>附录</h2><p>按服务和资源配置顺序，依次如下</p><h3 id=custom-nfs-server-rcyaml>custom-nfs-server-rc.yaml</h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-yaml data-lang=yaml><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>v1</span><span class=w>
</span><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>ReplicationController</span><span class=w>
</span><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>nfs-server</span><span class=w>
</span><span class=w></span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>replicas</span><span class=p>:</span><span class=w> </span><span class=m>1</span><span class=w>
</span><span class=w>  </span><span class=nt>selector</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>role</span><span class=p>:</span><span class=w> </span><span class=l>nfs-server</span><span class=w>
</span><span class=w>  </span><span class=nt>template</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span><span class=w>      </span><span class=nt>labels</span><span class=p>:</span><span class=w>
</span><span class=w>        </span><span class=nt>role</span><span class=p>:</span><span class=w> </span><span class=l>nfs-server</span><span class=w>
</span><span class=w>    </span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span><span class=w>      </span><span class=nt>containers</span><span class=p>:</span><span class=w>
</span><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>nfs-server</span><span class=w>
</span><span class=w>        </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>k8s.gcr.io/volume-nfs:0.8</span><span class=w>
</span><span class=w>        </span><span class=nt>ports</span><span class=p>:</span><span class=w>
</span><span class=w>          </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>nfs</span><span class=w>
</span><span class=w>            </span><span class=nt>containerPort</span><span class=p>:</span><span class=w> </span><span class=m>2049</span><span class=w>
</span><span class=w>          </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>mountd</span><span class=w>
</span><span class=w>            </span><span class=nt>containerPort</span><span class=p>:</span><span class=w> </span><span class=m>20048</span><span class=w>
</span><span class=w>          </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>rpcbind</span><span class=w>
</span><span class=w>            </span><span class=nt>containerPort</span><span class=p>:</span><span class=w> </span><span class=m>111</span><span class=w>
</span><span class=w>        </span><span class=nt>securityContext</span><span class=p>:</span><span class=w>
</span><span class=w>          </span><span class=nt>privileged</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span><span class=w>        </span><span class=nt>volumeMounts</span><span class=p>:</span><span class=w>
</span><span class=w>          </span>- <span class=nt>mountPath</span><span class=p>:</span><span class=w> </span><span class=l>/exports</span><span class=w>
</span><span class=w>            </span><span class=c># name: mypvc</span><span class=w>
</span><span class=w>            </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>data-volume</span><span class=w>
</span><span class=w>      </span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span><span class=w>        </span><span class=c># - name: mypvc</span><span class=w>
</span><span class=w>        </span><span class=c>#   persistentVolumeClaim:</span><span class=w>
</span><span class=w>        </span><span class=c>#     claimName: nfs-pv-provisioning-demo</span><span class=w>
</span><span class=w>        </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>data-volume                  </span><span class=w> </span><span class=c>#卷名</span><span class=w>
</span><span class=w>          </span><span class=nt>hostPath</span><span class=p>:</span><span class=w>
</span><span class=w>            </span><span class=nt>path</span><span class=p>:</span><span class=w> </span><span class=l>/tmp/data</span><span class=w>
</span></code></pre></td></tr></table></div></div><h3 id=custom-nfs-pvyaml>custom-nfs-pv.yaml</h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-yaml data-lang=yaml><span class=w>
</span><span class=w></span><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>v1</span><span class=w>
</span><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>PersistentVolume</span><span class=w>
</span><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>nfs</span><span class=w>
</span><span class=w></span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>capacity</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>storage</span><span class=p>:</span><span class=w> </span><span class=l>1Mi</span><span class=w>
</span><span class=w>  </span><span class=nt>accessModes</span><span class=p>:</span><span class=w>
</span><span class=w>    </span>- <span class=l>ReadWriteMany</span><span class=w>
</span><span class=w>    </span><span class=c>#- ReadWriteOnce</span><span class=w>
</span><span class=w>  </span><span class=nt>nfs</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=c># faild: nfs-server svc name</span><span class=w>
</span><span class=w>    </span><span class=c>#server: nfs-server.default.svc.cluster.local</span><span class=w>
</span><span class=w>    </span><span class=c># success: nfs-server svc ip</span><span class=w>
</span><span class=w>    </span><span class=nt>server</span><span class=p>:</span><span class=w> </span><span class=m>10.233.16.102</span><span class=w>
</span><span class=w>    </span><span class=nt>path</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;/exports&#34;</span><span class=w>
</span><span class=w>
</span></code></pre></td></tr></table></div></div><h3 id=custom-nfs-pvcyaml>custom-nfs-pvc.yaml</h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-yaml data-lang=yaml><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>v1</span><span class=w>
</span><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>PersistentVolumeClaim</span><span class=w>
</span><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>nfs</span><span class=w>
</span><span class=w></span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>accessModes</span><span class=p>:</span><span class=w>
</span><span class=w>    </span>- <span class=l>ReadWriteMany</span><span class=w>
</span><span class=w>    </span><span class=c>#- ReadWriteOnce</span><span class=w>
</span><span class=w>  </span><span class=nt>storageClassName</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;&#34;</span><span class=w>
</span><span class=w>  </span><span class=nt>resources</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>requests</span><span class=p>:</span><span class=w>
</span><span class=w>      </span><span class=nt>storage</span><span class=p>:</span><span class=w> </span><span class=l>1Mi</span><span class=w>
</span><span class=w>
</span></code></pre></td></tr></table></div></div><h3 id=custom-nfs-busybox-rcyaml>custom-nfs-busybox-rc.yaml</h3><p>使用pvc进行nfs存储写操作</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-yaml data-lang=yaml><span class=c># This mounts the nfs volume claim into /mnt and continuously</span><span class=w>
</span><span class=w></span><span class=c># overwrites /mnt/index.html with the time and hostname of the pod.</span><span class=w>
</span><span class=w>
</span><span class=w></span><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>v1</span><span class=w>
</span><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>ReplicationController</span><span class=w>
</span><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>nfs-busybox</span><span class=w>
</span><span class=w></span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>replicas</span><span class=p>:</span><span class=w> </span><span class=m>2</span><span class=w>
</span><span class=w>  </span><span class=nt>selector</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>nfs-busybox</span><span class=w>
</span><span class=w>  </span><span class=nt>template</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span><span class=w>      </span><span class=nt>labels</span><span class=p>:</span><span class=w>
</span><span class=w>        </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>nfs-busybox</span><span class=w>
</span><span class=w>    </span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span><span class=w>      </span><span class=nt>containers</span><span class=p>:</span><span class=w>
</span><span class=w>      </span>- <span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>busybox</span><span class=w>
</span><span class=w>        </span><span class=nt>command</span><span class=p>:</span><span class=w>
</span><span class=w>          </span>- <span class=l>sh</span><span class=w>
</span><span class=w>          </span>- -<span class=l>c</span><span class=w>
</span><span class=w>          </span>- <span class=s1>&#39;while true; do date &gt; /mnt/index.html; hostname &gt;&gt; /mnt/index.html; sleep $(($RANDOM % 5 + 5)); done&#39;</span><span class=w>
</span><span class=w>        </span><span class=nt>imagePullPolicy</span><span class=p>:</span><span class=w> </span><span class=l>IfNotPresent</span><span class=w>
</span><span class=w>        </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>busybox</span><span class=w>
</span><span class=w>        </span><span class=nt>volumeMounts</span><span class=p>:</span><span class=w>
</span><span class=w>          </span><span class=c># name must match the volume name below</span><span class=w>
</span><span class=w>          </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>nfs</span><span class=w>
</span><span class=w>            </span><span class=nt>mountPath</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;/mnt&#34;</span><span class=w>
</span><span class=w>      </span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>nfs</span><span class=w>
</span><span class=w>        </span><span class=nt>persistentVolumeClaim</span><span class=p>:</span><span class=w>
</span><span class=w>          </span><span class=nt>claimName</span><span class=p>:</span><span class=w> </span><span class=l>nfs</span><span class=w>
</span><span class=w>
</span><span class=w>
</span></code></pre></td></tr></table></div></div><h3 id=nfs-web-rcyaml>nfs-web-rc.yaml</h3><p>使用pvc进行nfs存储读操作</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-yaml data-lang=yaml><span class=c># This pod mounts the nfs volume claim into /usr/share/nginx/html and</span><span class=w>
</span><span class=w></span><span class=c># serves a simple web page.</span><span class=w>
</span><span class=w>
</span><span class=w></span><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>v1</span><span class=w>
</span><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>ReplicationController</span><span class=w>
</span><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>nfs-web</span><span class=w>
</span><span class=w></span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>replicas</span><span class=p>:</span><span class=w> </span><span class=m>2</span><span class=w>
</span><span class=w>  </span><span class=nt>selector</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>role</span><span class=p>:</span><span class=w> </span><span class=l>web-frontend</span><span class=w>
</span><span class=w>  </span><span class=nt>template</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span><span class=w>      </span><span class=nt>labels</span><span class=p>:</span><span class=w>
</span><span class=w>        </span><span class=nt>role</span><span class=p>:</span><span class=w> </span><span class=l>web-frontend</span><span class=w>
</span><span class=w>    </span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span><span class=w>      </span><span class=nt>containers</span><span class=p>:</span><span class=w>
</span><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>web</span><span class=w>
</span><span class=w>        </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>nginx:1.19</span><span class=w>
</span><span class=w>        </span><span class=nt>ports</span><span class=p>:</span><span class=w>
</span><span class=w>          </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>web</span><span class=w>
</span><span class=w>            </span><span class=nt>containerPort</span><span class=p>:</span><span class=w> </span><span class=m>80</span><span class=w>
</span><span class=w>        </span><span class=nt>volumeMounts</span><span class=p>:</span><span class=w>
</span><span class=w>            </span><span class=c># name must match the volume name below</span><span class=w>
</span><span class=w>            </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>nfs</span><span class=w>
</span><span class=w>              </span><span class=nt>mountPath</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;/usr/share/nginx/html&#34;</span><span class=w>
</span><span class=w>      </span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>nfs</span><span class=w>
</span><span class=w>        </span><span class=nt>persistentVolumeClaim</span><span class=p>:</span><span class=w>
</span><span class=w>          </span><span class=nt>claimName</span><span class=p>:</span><span class=w> </span><span class=l>nfs</span><span class=w>
</span><span class=w>
</span></code></pre></td></tr></table></div></div><p>pv和pvc结构体</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>  1
</span><span class=lnt>  2
</span><span class=lnt>  3
</span><span class=lnt>  4
</span><span class=lnt>  5
</span><span class=lnt>  6
</span><span class=lnt>  7
</span><span class=lnt>  8
</span><span class=lnt>  9
</span><span class=lnt> 10
</span><span class=lnt> 11
</span><span class=lnt> 12
</span><span class=lnt> 13
</span><span class=lnt> 14
</span><span class=lnt> 15
</span><span class=lnt> 16
</span><span class=lnt> 17
</span><span class=lnt> 18
</span><span class=lnt> 19
</span><span class=lnt> 20
</span><span class=lnt> 21
</span><span class=lnt> 22
</span><span class=lnt> 23
</span><span class=lnt> 24
</span><span class=lnt> 25
</span><span class=lnt> 26
</span><span class=lnt> 27
</span><span class=lnt> 28
</span><span class=lnt> 29
</span><span class=lnt> 30
</span><span class=lnt> 31
</span><span class=lnt> 32
</span><span class=lnt> 33
</span><span class=lnt> 34
</span><span class=lnt> 35
</span><span class=lnt> 36
</span><span class=lnt> 37
</span><span class=lnt> 38
</span><span class=lnt> 39
</span><span class=lnt> 40
</span><span class=lnt> 41
</span><span class=lnt> 42
</span><span class=lnt> 43
</span><span class=lnt> 44
</span><span class=lnt> 45
</span><span class=lnt> 46
</span><span class=lnt> 47
</span><span class=lnt> 48
</span><span class=lnt> 49
</span><span class=lnt> 50
</span><span class=lnt> 51
</span><span class=lnt> 52
</span><span class=lnt> 53
</span><span class=lnt> 54
</span><span class=lnt> 55
</span><span class=lnt> 56
</span><span class=lnt> 57
</span><span class=lnt> 58
</span><span class=lnt> 59
</span><span class=lnt> 60
</span><span class=lnt> 61
</span><span class=lnt> 62
</span><span class=lnt> 63
</span><span class=lnt> 64
</span><span class=lnt> 65
</span><span class=lnt> 66
</span><span class=lnt> 67
</span><span class=lnt> 68
</span><span class=lnt> 69
</span><span class=lnt> 70
</span><span class=lnt> 71
</span><span class=lnt> 72
</span><span class=lnt> 73
</span><span class=lnt> 74
</span><span class=lnt> 75
</span><span class=lnt> 76
</span><span class=lnt> 77
</span><span class=lnt> 78
</span><span class=lnt> 79
</span><span class=lnt> 80
</span><span class=lnt> 81
</span><span class=lnt> 82
</span><span class=lnt> 83
</span><span class=lnt> 84
</span><span class=lnt> 85
</span><span class=lnt> 86
</span><span class=lnt> 87
</span><span class=lnt> 88
</span><span class=lnt> 89
</span><span class=lnt> 90
</span><span class=lnt> 91
</span><span class=lnt> 92
</span><span class=lnt> 93
</span><span class=lnt> 94
</span><span class=lnt> 95
</span><span class=lnt> 96
</span><span class=lnt> 97
</span><span class=lnt> 98
</span><span class=lnt> 99
</span><span class=lnt>100
</span><span class=lnt>101
</span><span class=lnt>102
</span><span class=lnt>103
</span><span class=lnt>104
</span><span class=lnt>105
</span><span class=lnt>106
</span><span class=lnt>107
</span><span class=lnt>108
</span><span class=lnt>109
</span><span class=lnt>110
</span><span class=lnt>111
</span><span class=lnt>112
</span><span class=lnt>113
</span><span class=lnt>114
</span><span class=lnt>115
</span><span class=lnt>116
</span><span class=lnt>117
</span><span class=lnt>118
</span><span class=lnt>119
</span><span class=lnt>120
</span><span class=lnt>121
</span><span class=lnt>122
</span><span class=lnt>123
</span><span class=lnt>124
</span><span class=lnt>125
</span><span class=lnt>126
</span><span class=lnt>127
</span><span class=lnt>128
</span><span class=lnt>129
</span><span class=lnt>130
</span><span class=lnt>131
</span><span class=lnt>132
</span><span class=lnt>133
</span><span class=lnt>134
</span><span class=lnt>135
</span><span class=lnt>136
</span><span class=lnt>137
</span><span class=lnt>138
</span><span class=lnt>139
</span><span class=lnt>140
</span><span class=lnt>141
</span><span class=lnt>142
</span><span class=lnt>143
</span><span class=lnt>144
</span><span class=lnt>145
</span><span class=lnt>146
</span><span class=lnt>147
</span><span class=lnt>148
</span><span class=lnt>149
</span><span class=lnt>150
</span><span class=lnt>151
</span><span class=lnt>152
</span><span class=lnt>153
</span><span class=lnt>154
</span><span class=lnt>155
</span><span class=lnt>156
</span><span class=lnt>157
</span><span class=lnt>158
</span><span class=lnt>159
</span><span class=lnt>160
</span><span class=lnt>161
</span><span class=lnt>162
</span><span class=lnt>163
</span><span class=lnt>164
</span><span class=lnt>165
</span><span class=lnt>166
</span><span class=lnt>167
</span><span class=lnt>168
</span><span class=lnt>169
</span><span class=lnt>170
</span><span class=lnt>171
</span><span class=lnt>172
</span><span class=lnt>173
</span><span class=lnt>174
</span><span class=lnt>175
</span><span class=lnt>176
</span><span class=lnt>177
</span><span class=lnt>178
</span><span class=lnt>179
</span><span class=lnt>180
</span><span class=lnt>181
</span><span class=lnt>182
</span><span class=lnt>183
</span><span class=lnt>184
</span><span class=lnt>185
</span><span class=lnt>186
</span><span class=lnt>187
</span><span class=lnt>188
</span><span class=lnt>189
</span><span class=lnt>190
</span><span class=lnt>191
</span><span class=lnt>192
</span><span class=lnt>193
</span><span class=lnt>194
</span><span class=lnt>195
</span><span class=lnt>196
</span><span class=lnt>197
</span><span class=lnt>198
</span><span class=lnt>199
</span><span class=lnt>200
</span><span class=lnt>201
</span><span class=lnt>202
</span><span class=lnt>203
</span><span class=lnt>204
</span><span class=lnt>205
</span><span class=lnt>206
</span><span class=lnt>207
</span><span class=lnt>208
</span><span class=lnt>209
</span><span class=lnt>210
</span><span class=lnt>211
</span><span class=lnt>212
</span><span class=lnt>213
</span><span class=lnt>214
</span><span class=lnt>215
</span><span class=lnt>216
</span><span class=lnt>217
</span><span class=lnt>218
</span><span class=lnt>219
</span><span class=lnt>220
</span><span class=lnt>221
</span><span class=lnt>222
</span><span class=lnt>223
</span><span class=lnt>224
</span><span class=lnt>225
</span><span class=lnt>226
</span><span class=lnt>227
</span><span class=lnt>228
</span><span class=lnt>229
</span><span class=lnt>230
</span><span class=lnt>231
</span><span class=lnt>232
</span><span class=lnt>233
</span><span class=lnt>234
</span><span class=lnt>235
</span><span class=lnt>236
</span><span class=lnt>237
</span><span class=lnt>238
</span><span class=lnt>239
</span><span class=lnt>240
</span><span class=lnt>241
</span><span class=lnt>242
</span><span class=lnt>243
</span><span class=lnt>244
</span><span class=lnt>245
</span><span class=lnt>246
</span><span class=lnt>247
</span><span class=lnt>248
</span><span class=lnt>249
</span><span class=lnt>250
</span><span class=lnt>251
</span><span class=lnt>252
</span><span class=lnt>253
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-golang data-lang=golang>
<span class=c1>// Volume represents a named volume in a pod that may be accessed by any container in the pod.
</span><span class=c1></span><span class=kd>type</span> <span class=nx>Volume</span> <span class=kd>struct</span> <span class=p>{</span>
    <span class=c1>// Volume&#39;s name.
</span><span class=c1></span>    <span class=c1>// Must be a DNS_LABEL and unique within the pod.
</span><span class=c1></span>    <span class=c1>// More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
</span><span class=c1></span>    <span class=nx>Name</span> <span class=kt>string</span> <span class=s>`json:&#34;name&#34; protobuf:&#34;bytes,1,opt,name=name&#34;`</span>
    <span class=c1>// VolumeSource represents the location and type of the mounted volume.
</span><span class=c1></span>    <span class=c1>// If not specified, the Volume is implied to be an EmptyDir.
</span><span class=c1></span>    <span class=c1>// This implied behavior is deprecated and will be removed in a future version.
</span><span class=c1></span>    <span class=nx>VolumeSource</span> <span class=s>`json:&#34;,inline&#34; protobuf:&#34;bytes,2,opt,name=volumeSource&#34;`</span>
<span class=p>}</span>

<span class=c1>// Represents the source of a volume to mount.
</span><span class=c1>// Only one of its members may be specified.
</span><span class=c1></span><span class=kd>type</span> <span class=nx>VolumeSource</span> <span class=kd>struct</span> <span class=p>{</span>
    <span class=c1>// HostPath represents a pre-existing file or directory on the host
</span><span class=c1></span>    <span class=c1>// machine that is directly exposed to the container. This is generally
</span><span class=c1></span>    <span class=c1>// used for system agents or other privileged things that are allowed
</span><span class=c1></span>    <span class=c1>// to see the host machine. Most containers will NOT need this.
</span><span class=c1></span>    <span class=c1>// More info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath
</span><span class=c1></span>    <span class=c1>// ---
</span><span class=c1></span>    <span class=c1>// TODO(jonesdl) We need to restrict who can use host directory mounts and who can/can not
</span><span class=c1></span>    <span class=c1>// mount host directories as read/write.
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>HostPath</span> <span class=o>*</span><span class=nx>HostPathVolumeSource</span> <span class=s>`json:&#34;hostPath,omitempty&#34; protobuf:&#34;bytes,1,opt,name=hostPath&#34;`</span>
    <span class=c1>// EmptyDir represents a temporary directory that shares a pod&#39;s lifetime.
</span><span class=c1></span>    <span class=c1>// More info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>EmptyDir</span> <span class=o>*</span><span class=nx>EmptyDirVolumeSource</span> <span class=s>`json:&#34;emptyDir,omitempty&#34; protobuf:&#34;bytes,2,opt,name=emptyDir&#34;`</span>
    <span class=c1>// GCEPersistentDisk represents a GCE Disk resource that is attached to a
</span><span class=c1></span>    <span class=c1>// kubelet&#39;s host machine and then exposed to the pod.
</span><span class=c1></span>    <span class=c1>// More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>GCEPersistentDisk</span> <span class=o>*</span><span class=nx>GCEPersistentDiskVolumeSource</span> <span class=s>`json:&#34;gcePersistentDisk,omitempty&#34; protobuf:&#34;bytes,3,opt,name=gcePersistentDisk&#34;`</span>
    <span class=c1>// AWSElasticBlockStore represents an AWS Disk resource that is attached to a
</span><span class=c1></span>    <span class=c1>// kubelet&#39;s host machine and then exposed to the pod.
</span><span class=c1></span>    <span class=c1>// More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>AWSElasticBlockStore</span> <span class=o>*</span><span class=nx>AWSElasticBlockStoreVolumeSource</span> <span class=s>`json:&#34;awsElasticBlockStore,omitempty&#34; protobuf:&#34;bytes,4,opt,name=awsElasticBlockStore&#34;`</span>
    <span class=c1>// GitRepo represents a git repository at a particular revision.
</span><span class=c1></span>    <span class=c1>// DEPRECATED: GitRepo is deprecated. To provision a container with a git repo, mount an
</span><span class=c1></span>    <span class=c1>// EmptyDir into an InitContainer that clones the repo using git, then mount the EmptyDir
</span><span class=c1></span>    <span class=c1>// into the Pod&#39;s container.
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>GitRepo</span> <span class=o>*</span><span class=nx>GitRepoVolumeSource</span> <span class=s>`json:&#34;gitRepo,omitempty&#34; protobuf:&#34;bytes,5,opt,name=gitRepo&#34;`</span>
    <span class=c1>// Secret represents a secret that should populate this volume.
</span><span class=c1></span>    <span class=c1>// More info: https://kubernetes.io/docs/concepts/storage/volumes#secret
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>Secret</span> <span class=o>*</span><span class=nx>SecretVolumeSource</span> <span class=s>`json:&#34;secret,omitempty&#34; protobuf:&#34;bytes,6,opt,name=secret&#34;`</span>
    <span class=c1>// NFS represents an NFS mount on the host that shares a pod&#39;s lifetime
</span><span class=c1></span>    <span class=c1>// More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>NFS</span> <span class=o>*</span><span class=nx>NFSVolumeSource</span> <span class=s>`json:&#34;nfs,omitempty&#34; protobuf:&#34;bytes,7,opt,name=nfs&#34;`</span>
    <span class=c1>// ISCSI represents an ISCSI Disk resource that is attached to a
</span><span class=c1></span>    <span class=c1>// kubelet&#39;s host machine and then exposed to the pod.
</span><span class=c1></span>    <span class=c1>// More info: https://examples.k8s.io/volumes/iscsi/README.md
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>ISCSI</span> <span class=o>*</span><span class=nx>ISCSIVolumeSource</span> <span class=s>`json:&#34;iscsi,omitempty&#34; protobuf:&#34;bytes,8,opt,name=iscsi&#34;`</span>
    <span class=c1>// Glusterfs represents a Glusterfs mount on the host that shares a pod&#39;s lifetime.
</span><span class=c1></span>    <span class=c1>// More info: https://examples.k8s.io/volumes/glusterfs/README.md
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>Glusterfs</span> <span class=o>*</span><span class=nx>GlusterfsVolumeSource</span> <span class=s>`json:&#34;glusterfs,omitempty&#34; protobuf:&#34;bytes,9,opt,name=glusterfs&#34;`</span>
    <span class=c1>// PersistentVolumeClaimVolumeSource represents a reference to a
</span><span class=c1></span>    <span class=c1>// PersistentVolumeClaim in the same namespace.
</span><span class=c1></span>    <span class=c1>// More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>PersistentVolumeClaim</span> <span class=o>*</span><span class=nx>PersistentVolumeClaimVolumeSource</span> <span class=s>`json:&#34;persistentVolumeClaim,omitempty&#34; protobuf:&#34;bytes,10,opt,name=persistentVolumeClaim&#34;`</span>
    <span class=c1>// RBD represents a Rados Block Device mount on the host that shares a pod&#39;s lifetime.
</span><span class=c1></span>    <span class=c1>// More info: https://examples.k8s.io/volumes/rbd/README.md
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>RBD</span> <span class=o>*</span><span class=nx>RBDVolumeSource</span> <span class=s>`json:&#34;rbd,omitempty&#34; protobuf:&#34;bytes,11,opt,name=rbd&#34;`</span>
    <span class=c1>// FlexVolume represents a generic volume resource that is
</span><span class=c1></span>    <span class=c1>// provisioned/attached using an exec based plugin.
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>FlexVolume</span> <span class=o>*</span><span class=nx>FlexVolumeSource</span> <span class=s>`json:&#34;flexVolume,omitempty&#34; protobuf:&#34;bytes,12,opt,name=flexVolume&#34;`</span>
    <span class=c1>// Cinder represents a cinder volume attached and mounted on kubelets host machine.
</span><span class=c1></span>    <span class=c1>// More info: https://examples.k8s.io/mysql-cinder-pd/README.md
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>Cinder</span> <span class=o>*</span><span class=nx>CinderVolumeSource</span> <span class=s>`json:&#34;cinder,omitempty&#34; protobuf:&#34;bytes,13,opt,name=cinder&#34;`</span>
    <span class=c1>// CephFS represents a Ceph FS mount on the host that shares a pod&#39;s lifetime
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>CephFS</span> <span class=o>*</span><span class=nx>CephFSVolumeSource</span> <span class=s>`json:&#34;cephfs,omitempty&#34; protobuf:&#34;bytes,14,opt,name=cephfs&#34;`</span>
    <span class=c1>// Flocker represents a Flocker volume attached to a kubelet&#39;s host machine. This depends on the Flocker control service being running
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>Flocker</span> <span class=o>*</span><span class=nx>FlockerVolumeSource</span> <span class=s>`json:&#34;flocker,omitempty&#34; protobuf:&#34;bytes,15,opt,name=flocker&#34;`</span>
    <span class=c1>// DownwardAPI represents downward API about the pod that should populate this volume
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>DownwardAPI</span> <span class=o>*</span><span class=nx>DownwardAPIVolumeSource</span> <span class=s>`json:&#34;downwardAPI,omitempty&#34; protobuf:&#34;bytes,16,opt,name=downwardAPI&#34;`</span>
    <span class=c1>// FC represents a Fibre Channel resource that is attached to a kubelet&#39;s host machine and then exposed to the pod.
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>FC</span> <span class=o>*</span><span class=nx>FCVolumeSource</span> <span class=s>`json:&#34;fc,omitempty&#34; protobuf:&#34;bytes,17,opt,name=fc&#34;`</span>
    <span class=c1>// AzureFile represents an Azure File Service mount on the host and bind mount to the pod.
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>AzureFile</span> <span class=o>*</span><span class=nx>AzureFileVolumeSource</span> <span class=s>`json:&#34;azureFile,omitempty&#34; protobuf:&#34;bytes,18,opt,name=azureFile&#34;`</span>
    <span class=c1>// ConfigMap represents a configMap that should populate this volume
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>ConfigMap</span> <span class=o>*</span><span class=nx>ConfigMapVolumeSource</span> <span class=s>`json:&#34;configMap,omitempty&#34; protobuf:&#34;bytes,19,opt,name=configMap&#34;`</span>
    <span class=c1>// VsphereVolume represents a vSphere volume attached and mounted on kubelets host machine
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>VsphereVolume</span> <span class=o>*</span><span class=nx>VsphereVirtualDiskVolumeSource</span> <span class=s>`json:&#34;vsphereVolume,omitempty&#34; protobuf:&#34;bytes,20,opt,name=vsphereVolume&#34;`</span>
    <span class=c1>// Quobyte represents a Quobyte mount on the host that shares a pod&#39;s lifetime
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>Quobyte</span> <span class=o>*</span><span class=nx>QuobyteVolumeSource</span> <span class=s>`json:&#34;quobyte,omitempty&#34; protobuf:&#34;bytes,21,opt,name=quobyte&#34;`</span>
    <span class=c1>// AzureDisk represents an Azure Data Disk mount on the host and bind mount to the pod.
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>AzureDisk</span> <span class=o>*</span><span class=nx>AzureDiskVolumeSource</span> <span class=s>`json:&#34;azureDisk,omitempty&#34; protobuf:&#34;bytes,22,opt,name=azureDisk&#34;`</span>
    <span class=c1>// PhotonPersistentDisk represents a PhotonController persistent disk attached and mounted on kubelets host machine
</span><span class=c1></span>    <span class=nx>PhotonPersistentDisk</span> <span class=o>*</span><span class=nx>PhotonPersistentDiskVolumeSource</span> <span class=s>`json:&#34;photonPersistentDisk,omitempty&#34; protobuf:&#34;bytes,23,opt,name=photonPersistentDisk&#34;`</span>
    <span class=c1>// Items for all in one resources secrets, configmaps, and downward API
</span><span class=c1></span>    <span class=nx>Projected</span> <span class=o>*</span><span class=nx>ProjectedVolumeSource</span> <span class=s>`json:&#34;projected,omitempty&#34; protobuf:&#34;bytes,26,opt,name=projected&#34;`</span>
    <span class=c1>// PortworxVolume represents a portworx volume attached and mounted on kubelets host machine
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>PortworxVolume</span> <span class=o>*</span><span class=nx>PortworxVolumeSource</span> <span class=s>`json:&#34;portworxVolume,omitempty&#34; protobuf:&#34;bytes,24,opt,name=portworxVolume&#34;`</span>
    <span class=c1>// ScaleIO represents a ScaleIO persistent volume attached and mounted on Kubernetes nodes.
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>ScaleIO</span> <span class=o>*</span><span class=nx>ScaleIOVolumeSource</span> <span class=s>`json:&#34;scaleIO,omitempty&#34; protobuf:&#34;bytes,25,opt,name=scaleIO&#34;`</span>
    <span class=c1>// StorageOS represents a StorageOS volume attached and mounted on Kubernetes nodes.
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>StorageOS</span> <span class=o>*</span><span class=nx>StorageOSVolumeSource</span> <span class=s>`json:&#34;storageos,omitempty&#34; protobuf:&#34;bytes,27,opt,name=storageos&#34;`</span>
    <span class=c1>// CSI (Container Storage Interface) represents ephemeral storage that is handled by certain external CSI drivers (Beta feature).
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>CSI</span> <span class=o>*</span><span class=nx>CSIVolumeSource</span> <span class=s>`json:&#34;csi,omitempty&#34; protobuf:&#34;bytes,28,opt,name=csi&#34;`</span>
    <span class=c1>// Ephemeral represents a volume that is handled by a cluster storage driver (Alpha feature).
</span><span class=c1></span>    <span class=c1>// The volume&#39;s lifecycle is tied to the pod that defines it - it will be created before the pod starts,
</span><span class=c1></span>    <span class=c1>// and deleted when the pod is removed.
</span><span class=c1></span>    <span class=c1>//
</span><span class=c1></span>    <span class=c1>// Use this if:
</span><span class=c1></span>    <span class=c1>// a) the volume is only needed while the pod runs,
</span><span class=c1></span>    <span class=c1>// b) features of normal volumes like restoring from snapshot or capacity
</span><span class=c1></span>    <span class=c1>//    tracking are needed,
</span><span class=c1></span>    <span class=c1>// c) the storage driver is specified through a storage class, and
</span><span class=c1></span>    <span class=c1>// d) the storage driver supports dynamic volume provisioning through
</span><span class=c1></span>    <span class=c1>//    a PersistentVolumeClaim (see EphemeralVolumeSource for more
</span><span class=c1></span>    <span class=c1>//    information on the connection between this volume type
</span><span class=c1></span>    <span class=c1>//    and PersistentVolumeClaim).
</span><span class=c1></span>    <span class=c1>//
</span><span class=c1></span>    <span class=c1>// Use PersistentVolumeClaim or one of the vendor-specific
</span><span class=c1></span>    <span class=c1>// APIs for volumes that persist for longer than the lifecycle
</span><span class=c1></span>    <span class=c1>// of an individual pod.
</span><span class=c1></span>    <span class=c1>//
</span><span class=c1></span>    <span class=c1>// Use CSI for light-weight local ephemeral volumes if the CSI driver is meant to
</span><span class=c1></span>    <span class=c1>// be used that way - see the documentation of the driver for
</span><span class=c1></span>    <span class=c1>// more information.
</span><span class=c1></span>    <span class=c1>//
</span><span class=c1></span>    <span class=c1>// A pod can use both types of ephemeral volumes and
</span><span class=c1></span>    <span class=c1>// persistent volumes at the same time.
</span><span class=c1></span>    <span class=c1>//
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>Ephemeral</span> <span class=o>*</span><span class=nx>EphemeralVolumeSource</span> <span class=s>`json:&#34;ephemeral,omitempty&#34; protobuf:&#34;bytes,29,opt,name=ephemeral&#34;`</span>
<span class=p>}</span>

<span class=c1>// PersistentVolumeClaimVolumeSource references the user&#39;s PVC in the same namespace.
</span><span class=c1>// This volume finds the bound PV and mounts that volume for the pod. A
</span><span class=c1>// PersistentVolumeClaimVolumeSource is, essentially, a wrapper around another
</span><span class=c1>// type of volume that is owned by someone else (the system).
</span><span class=c1></span><span class=kd>type</span> <span class=nx>PersistentVolumeClaimVolumeSource</span> <span class=kd>struct</span> <span class=p>{</span>
    <span class=c1>// ClaimName is the name of a PersistentVolumeClaim in the same namespace as the pod using this volume.
</span><span class=c1></span>    <span class=c1>// More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
</span><span class=c1></span>    <span class=nx>ClaimName</span> <span class=kt>string</span> <span class=s>`json:&#34;claimName&#34; protobuf:&#34;bytes,1,opt,name=claimName&#34;`</span>
    <span class=c1>// Will force the ReadOnly setting in VolumeMounts.
</span><span class=c1></span>    <span class=c1>// Default false.
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>ReadOnly</span> <span class=kt>bool</span> <span class=s>`json:&#34;readOnly,omitempty&#34; protobuf:&#34;varint,2,opt,name=readOnly&#34;`</span>
<span class=p>}</span>

<span class=c1>// PersistentVolumeSource is similar to VolumeSource but meant for the
</span><span class=c1>// administrator who creates PVs. Exactly one of its members must be set.
</span><span class=c1></span><span class=kd>type</span> <span class=nx>PersistentVolumeSource</span> <span class=kd>struct</span> <span class=p>{</span>
    <span class=c1>// GCEPersistentDisk represents a GCE Disk resource that is attached to a
</span><span class=c1></span>    <span class=c1>// kubelet&#39;s host machine and then exposed to the pod. Provisioned by an admin.
</span><span class=c1></span>    <span class=c1>// More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>GCEPersistentDisk</span> <span class=o>*</span><span class=nx>GCEPersistentDiskVolumeSource</span> <span class=s>`json:&#34;gcePersistentDisk,omitempty&#34; protobuf:&#34;bytes,1,opt,name=gcePersistentDisk&#34;`</span>
    <span class=c1>// AWSElasticBlockStore represents an AWS Disk resource that is attached to a
</span><span class=c1></span>    <span class=c1>// kubelet&#39;s host machine and then exposed to the pod.
</span><span class=c1></span>    <span class=c1>// More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>AWSElasticBlockStore</span> <span class=o>*</span><span class=nx>AWSElasticBlockStoreVolumeSource</span> <span class=s>`json:&#34;awsElasticBlockStore,omitempty&#34; protobuf:&#34;bytes,2,opt,name=awsElasticBlockStore&#34;`</span>
    <span class=c1>// HostPath represents a directory on the host.
</span><span class=c1></span>    <span class=c1>// Provisioned by a developer or tester.
</span><span class=c1></span>    <span class=c1>// This is useful for single-node development and testing only!
</span><span class=c1></span>    <span class=c1>// On-host storage is not supported in any way and WILL NOT WORK in a multi-node cluster.
</span><span class=c1></span>    <span class=c1>// More info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>HostPath</span> <span class=o>*</span><span class=nx>HostPathVolumeSource</span> <span class=s>`json:&#34;hostPath,omitempty&#34; protobuf:&#34;bytes,3,opt,name=hostPath&#34;`</span>
    <span class=c1>// Glusterfs represents a Glusterfs volume that is attached to a host and
</span><span class=c1></span>    <span class=c1>// exposed to the pod. Provisioned by an admin.
</span><span class=c1></span>    <span class=c1>// More info: https://examples.k8s.io/volumes/glusterfs/README.md
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>Glusterfs</span> <span class=o>*</span><span class=nx>GlusterfsPersistentVolumeSource</span> <span class=s>`json:&#34;glusterfs,omitempty&#34; protobuf:&#34;bytes,4,opt,name=glusterfs&#34;`</span>
    <span class=c1>// NFS represents an NFS mount on the host. Provisioned by an admin.
</span><span class=c1></span>    <span class=c1>// More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>NFS</span> <span class=o>*</span><span class=nx>NFSVolumeSource</span> <span class=s>`json:&#34;nfs,omitempty&#34; protobuf:&#34;bytes,5,opt,name=nfs&#34;`</span>
    <span class=c1>// RBD represents a Rados Block Device mount on the host that shares a pod&#39;s lifetime.
</span><span class=c1></span>    <span class=c1>// More info: https://examples.k8s.io/volumes/rbd/README.md
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>RBD</span> <span class=o>*</span><span class=nx>RBDPersistentVolumeSource</span> <span class=s>`json:&#34;rbd,omitempty&#34; protobuf:&#34;bytes,6,opt,name=rbd&#34;`</span>
    <span class=c1>// ISCSI represents an ISCSI Disk resource that is attached to a
</span><span class=c1></span>    <span class=c1>// kubelet&#39;s host machine and then exposed to the pod. Provisioned by an admin.
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>ISCSI</span> <span class=o>*</span><span class=nx>ISCSIPersistentVolumeSource</span> <span class=s>`json:&#34;iscsi,omitempty&#34; protobuf:&#34;bytes,7,opt,name=iscsi&#34;`</span>
    <span class=c1>// Cinder represents a cinder volume attached and mounted on kubelets host machine.
</span><span class=c1></span>    <span class=c1>// More info: https://examples.k8s.io/mysql-cinder-pd/README.md
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>Cinder</span> <span class=o>*</span><span class=nx>CinderPersistentVolumeSource</span> <span class=s>`json:&#34;cinder,omitempty&#34; protobuf:&#34;bytes,8,opt,name=cinder&#34;`</span>
    <span class=c1>// CephFS represents a Ceph FS mount on the host that shares a pod&#39;s lifetime
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>CephFS</span> <span class=o>*</span><span class=nx>CephFSPersistentVolumeSource</span> <span class=s>`json:&#34;cephfs,omitempty&#34; protobuf:&#34;bytes,9,opt,name=cephfs&#34;`</span>
    <span class=c1>// FC represents a Fibre Channel resource that is attached to a kubelet&#39;s host machine and then exposed to the pod.
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>FC</span> <span class=o>*</span><span class=nx>FCVolumeSource</span> <span class=s>`json:&#34;fc,omitempty&#34; protobuf:&#34;bytes,10,opt,name=fc&#34;`</span>
    <span class=c1>// Flocker represents a Flocker volume attached to a kubelet&#39;s host machine and exposed to the pod for its usage. This depends on the Flocker control service being running
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>Flocker</span> <span class=o>*</span><span class=nx>FlockerVolumeSource</span> <span class=s>`json:&#34;flocker,omitempty&#34; protobuf:&#34;bytes,11,opt,name=flocker&#34;`</span>
    <span class=c1>// FlexVolume represents a generic volume resource that is
</span><span class=c1></span>    <span class=c1>// provisioned/attached using an exec based plugin.
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>FlexVolume</span> <span class=o>*</span><span class=nx>FlexPersistentVolumeSource</span> <span class=s>`json:&#34;flexVolume,omitempty&#34; protobuf:&#34;bytes,12,opt,name=flexVolume&#34;`</span>
    <span class=c1>// AzureFile represents an Azure File Service mount on the host and bind mount to the pod.
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>AzureFile</span> <span class=o>*</span><span class=nx>AzureFilePersistentVolumeSource</span> <span class=s>`json:&#34;azureFile,omitempty&#34; protobuf:&#34;bytes,13,opt,name=azureFile&#34;`</span>
    <span class=c1>// VsphereVolume represents a vSphere volume attached and mounted on kubelets host machine
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>VsphereVolume</span> <span class=o>*</span><span class=nx>VsphereVirtualDiskVolumeSource</span> <span class=s>`json:&#34;vsphereVolume,omitempty&#34; protobuf:&#34;bytes,14,opt,name=vsphereVolume&#34;`</span>
    <span class=c1>// Quobyte represents a Quobyte mount on the host that shares a pod&#39;s lifetime
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>Quobyte</span> <span class=o>*</span><span class=nx>QuobyteVolumeSource</span> <span class=s>`json:&#34;quobyte,omitempty&#34; protobuf:&#34;bytes,15,opt,name=quobyte&#34;`</span>
    <span class=c1>// AzureDisk represents an Azure Data Disk mount on the host and bind mount to the pod.
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>AzureDisk</span> <span class=o>*</span><span class=nx>AzureDiskVolumeSource</span> <span class=s>`json:&#34;azureDisk,omitempty&#34; protobuf:&#34;bytes,16,opt,name=azureDisk&#34;`</span>
    <span class=c1>// PhotonPersistentDisk represents a PhotonController persistent disk attached and mounted on kubelets host machine
</span><span class=c1></span>    <span class=nx>PhotonPersistentDisk</span> <span class=o>*</span><span class=nx>PhotonPersistentDiskVolumeSource</span> <span class=s>`json:&#34;photonPersistentDisk,omitempty&#34; protobuf:&#34;bytes,17,opt,name=photonPersistentDisk&#34;`</span>
    <span class=c1>// PortworxVolume represents a portworx volume attached and mounted on kubelets host machine
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>PortworxVolume</span> <span class=o>*</span><span class=nx>PortworxVolumeSource</span> <span class=s>`json:&#34;portworxVolume,omitempty&#34; protobuf:&#34;bytes,18,opt,name=portworxVolume&#34;`</span>
    <span class=c1>// ScaleIO represents a ScaleIO persistent volume attached and mounted on Kubernetes nodes.
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>ScaleIO</span> <span class=o>*</span><span class=nx>ScaleIOPersistentVolumeSource</span> <span class=s>`json:&#34;scaleIO,omitempty&#34; protobuf:&#34;bytes,19,opt,name=scaleIO&#34;`</span>
    <span class=c1>// Local represents directly-attached storage with node affinity
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>Local</span> <span class=o>*</span><span class=nx>LocalVolumeSource</span> <span class=s>`json:&#34;local,omitempty&#34; protobuf:&#34;bytes,20,opt,name=local&#34;`</span>
    <span class=c1>// StorageOS represents a StorageOS volume that is attached to the kubelet&#39;s host machine and mounted into the pod
</span><span class=c1></span>    <span class=c1>// More info: https://examples.k8s.io/volumes/storageos/README.md
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>StorageOS</span> <span class=o>*</span><span class=nx>StorageOSPersistentVolumeSource</span> <span class=s>`json:&#34;storageos,omitempty&#34; protobuf:&#34;bytes,21,opt,name=storageos&#34;`</span>
    <span class=c1>// CSI represents storage that is handled by an external CSI driver (Beta feature).
</span><span class=c1></span>    <span class=c1>// +optional
</span><span class=c1></span>    <span class=nx>CSI</span> <span class=o>*</span><span class=nx>CSIPersistentVolumeSource</span> <span class=s>`json:&#34;csi,omitempty&#34; protobuf:&#34;bytes,22,opt,name=csi&#34;`</span>
<span class=p>}</span>


</code></pre></td></tr></table></div></div><h2 id=参考资料>参考资料</h2><ul><li><p><a href=https://kubernetes.io/zh/docs/concepts/storage/volumes/ target=_blank rel="noopener noreffer">volume概念</a></p></li><li><p><a href=https://kubernetes.io/zh/docs/concepts/storage/persistent-volumes/ target=_blank rel="noopener noreffer">persistent-volumes概念</a></p></li><li><p><a href=https://github.com/kubernetes/community/blob/master/contributors/design-proposals/storage/persistent-storage.md target=_blank rel="noopener noreffer">持久存储设计文档</a></p></li><li><p><a href=https://kubernetes.io/zh/docs/concepts/storage/storage-classes/ target=_blank rel="noopener noreffer">存储类StorageClass</a></p></li><li><p><a href=https://kubernetes.io/zh/docs/tasks/configure-pod-container/configure-persistent-volume-storage/ target=_blank rel="noopener noreffer">基于运行示例的详细演练</a></p></li><li><p><a href=https://blog.51cto.com/3241766/2435182 target=_blank rel="noopener noreffer">存储卷和数据持久化(Volumes and Persistent Storage)</a></p></li></ul></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>更新于 2021-02-03</span></div><div class=post-info-license></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fas fa-tags fa-fw"></i>&nbsp;<a href=/tags/k8s/>K8S</a></section><section><span><a href=javascript:void(0); onclick=window.history.back();>返回</a></span>&nbsp;|&nbsp;<span><a href=/>主页</a></span></section></div><div class=post-nav><a href=/posts/2021/01/hugepage%E9%85%8D%E7%BD%AE%E5%AF%BC%E8%87%B4k8s%E7%9A%84kubelet%E9%87%8D%E5%90%AF%E5%A4%B1%E8%B4%A5%E9%97%AE%E9%A2%98/ class=prev rel=prev title=hugepage配置导致k8s的kubelet重启失败问题><i class="fas fa-angle-left fa-fw"></i>hugepage配置导致k8s的kubelet重启失败问题</a>
<a href=/posts/2021/02/k8s%E7%9A%84%E4%B8%9A%E5%8A%A1pod%E7%BB%84%E4%BB%B6%E7%9A%84invalid-token%E9%97%AE%E9%A2%98/ class=next rel=next title="k8s的业务pod组件的invalid token问题">k8s的业务pod组件的invalid token问题<i class="fas fa-angle-right fa-fw"></i></a></div></div><div id=comments></div></article></div></main><footer class=footer><div class=footer-container><div class=footer-line><i class="far fa-copyright fa-fw"></i><span itemprop=copyrightYear>2016 - 2021</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=bingerambo.com target=_blank>Binge</a></span>&nbsp;|&nbsp;<span class=license><a rel="license external nofollow noopener noreffer" href=http://bingerambo.com/ target=_blank>bingerambo.com</a></span></div><div class=footer-line><i class="fa fa-eye"></i>本站总访问量<span id=busuanzi_value_site_pv></span>次
<script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script></div></div></footer></div><div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title=回到顶部><i class="fas fa-arrow-up fa-fw"></i></a><a href=# id=view-comments class=fixed-button title=查看评论><i class="fas fa-comment fa-fw"></i></a></div><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/lightgallery.js@1.2.0/dist/css/lightgallery.min.css><script type=text/javascript src=https://cdn.jsdelivr.net/npm/smooth-scroll@16.1.3/dist/smooth-scroll.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lazysizes@5.2.2/lazysizes.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lightgallery.js@1.2.0/dist/js/lightgallery.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lg-zoom.js@1.2.0/dist/lg-zoom.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/clipboard@2.0.6/dist/clipboard.min.js></script><script type=text/javascript>window.config={"code":{"copyTitle":"复制到剪贴板","maxShownLines":10},"comment":{},"lightGallery":{"actualSize":false,"exThumbImage":"data-thumbnail","hideBarsDelay":2000,"selector":".lightgallery","speed":400,"thumbContHeight":80,"thumbWidth":80,"thumbnail":true}};</script><script type=text/javascript src=/js/theme.min.js></script><script type=text/javascript>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}gtag('js',new Date());gtag('config','UA-81425808-1',{'anonymize_ip':true});</script><script type=text/javascript src="https://www.googletagmanager.com/gtag/js?id=UA-81425808-1" async></script><script src=https://libs.baidu.com/jquery/2.1.4/jquery.min.js></script><script src=https://cdn.bootcdn.net/ajax/libs/jquery-backstretch/2.1.18/jquery.backstretch.min.js></script><script type=text/javascript src=/js/custom.js></script><script>var _hmt=_hmt||[];(function(){var hm=document.createElement("script");hm.src="https://hm.baidu.com/hm.js?c0176279eee823ce422da4e8d06708f9";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(hm,s);})();</script></body></html>